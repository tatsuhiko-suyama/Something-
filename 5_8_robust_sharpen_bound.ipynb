{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJ8BpnkwfZZhF/6qG/Gyxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatsuhiko-suyama/Something-/blob/main/5_8_robust_sharpen_bound.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DdvPF6218NTO"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Classical MVP"
      ],
      "metadata": {
        "id": "SQBkFwO4_NuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "alpha0_classical_mv_unconstrained_target.py  –  α = 0 （古典的平均–分散ポートフォリオ、和の制約なし、目標リターンあり）\n",
        "    • sum pi = 1 の制約を外し、目標リターン mu_tilde を達成しつつ分散を最小化するポートフォリオを計算\n",
        "    • alpha_sweep_K4M4_SR.csv と互換な列構成で 1 行だけの CSV を生成\n",
        "    • SR_rob には計算されたポートフォリオの Sharpe を格納\n",
        "    • w*, λ, dpi* は NaN で空欄（robust 問題に固有の列のため）\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 0. IMPORTS & CONSTANTS\n",
        "# ---------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "K, M        = 4, 4\n",
        "mu_tilde    = 0.03           # 目標リターン (必要)\n",
        "alpha0      = 0.0            # 古典設定\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. SYNTHETIC DATA（元スクリプトと同一）\n",
        "# ---------------------------------------------------------------------\n",
        "r_base = np.array([0.02, 0.03, 0.04, 0.05])\n",
        "Delta_A = np.array([[+1, 1, -1, -1],\n",
        "                    [+1, 1, -1, -1],\n",
        "                    [+2, -1, +2, -2],\n",
        "                    [+2, -2, +2, -2]], dtype=float)\n",
        "Delta_r_m     = Delta_A / 1000\n",
        "sigma_base    = np.array([0.20, 0.25, 0.30, 0.35])\n",
        "Delta_sigma_m = Delta_A / 100\n",
        "\n",
        "def block_corr(rho_in: float, rho_out: float) -> np.ndarray:\n",
        "    C = np.full((K, K), rho_out)\n",
        "    np.fill_diagonal(C, 1.0)\n",
        "    sectA, sectB = [0, 1], [2, 3]\n",
        "    for i in sectA:\n",
        "        for j in sectA:\n",
        "            if i != j:\n",
        "                C[i, j] = rho_in\n",
        "    for i in sectB:\n",
        "        for j in sectB:\n",
        "            if i != j:\n",
        "                C[i, j] = rho_in\n",
        "    return C\n",
        "\n",
        "C_base = block_corr(0.75, 0.50)\n",
        "tilde_C_list = [\n",
        "    block_corr(0.85, 0.40),\n",
        "    block_corr(0.65, 0.40),\n",
        "    block_corr(0.65, 0.60),\n",
        "    block_corr(0.85, 0.60),\n",
        "]\n",
        "\n",
        "def mix_corr(C0, C1, alpha, beta=0.5, eps=1e-4):\n",
        "    C = (1 - beta * alpha) * C0 + beta * alpha * C1\n",
        "    eigval, eigvec = np.linalg.eigh(C)\n",
        "    eigval_clip = np.clip(eigval, eps, None)\n",
        "    C_spd = eigvec @ np.diag(eigval_clip) @ eigvec.T\n",
        "    D = np.sqrt(np.diag(C_spd))\n",
        "    return C_spd / np.outer(D, D)\n",
        "\n",
        "def build_params(alpha: float):\n",
        "    \"\"\"Return mean matrix R (K×M) and second-moment matrices Σ (K×K×M).\"\"\"\n",
        "    R = r_base[:, None] + alpha * Delta_r_m\n",
        "    Sigma = np.zeros((K, K, M))\n",
        "    for m in range(M):\n",
        "        sig_vec = sigma_base + alpha * Delta_sigma_m[:, m]\n",
        "        diag_sig = np.diag(sig_vec)\n",
        "        C_alpha = mix_corr(C_base, tilde_C_list[m], alpha, beta=0.5)\n",
        "        Sigma[:, :, m] = diag_sig @ C_alpha @ diag_sig + np.outer(R[:, m], R[:, m])\n",
        "    return R, Sigma\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. α = 0 の古典 MVP を厳密に解く（和の制約なし、目標リターン制約あり）\n",
        "# ---------------------------------------------------------------------\n",
        "R0, Sigma0_arr = build_params(alpha0)\n",
        "\n",
        "# モデル重みは一様  w_m = 1/M\n",
        "w_uniform = np.ones(M) / M\n",
        "# 平均リターンベクトルは、各モデルの期待リターンの平均とする\n",
        "r_bar     = R0 @ w_uniform\n",
        "\n",
        "# 共分散行列は、古典設定ではモデル0のデータから計算（元のスクリプトに従う）\n",
        "Cov_bar   = Sigma0_arr[:,:,0]-np.outer(R0[:,0],R0[:,0])\n",
        "\n",
        "# ---- 目標リターン mu_tilde を達成し、分散を最小化（和の制約なし）----\n",
        "# 最適解は pi = lambda * inv(Cov_bar) @ r_bar\n",
        "# 制約: r_bar^T @ pi = mu_tilde\n",
        "# r_bar^T @ (lambda * inv(Cov_bar) @ r_bar) = mu_tilde\n",
        "# lambda * (r_bar^T @ inv(Cov_bar) @ r_bar) = mu_tilde\n",
        "# lambda = mu_tilde / (r_bar^T @ inv(Cov_bar) @ r_bar)\n",
        "\n",
        "invC = np.linalg.inv(Cov_bar)\n",
        "\n",
        "# B_prime = r_bar^T @ invC @ r_bar  (これは元のスクリプトのCに等しい)\n",
        "B_prime = r_bar @ invC @ r_bar\n",
        "\n",
        "# lambda を計算 (ただし B_prime がゼロでないことを仮定)\n",
        "if B_prime < 1e-9: # ゼロに近い場合のエラー回避\n",
        "     raise ValueError(\"r_bar @ inv(Cov_bar) @ r_bar is close to zero. Cannot achieve target return.\")\n",
        "\n",
        "lam = mu_tilde / B_prime\n",
        "\n",
        "# 最適ポートフォリオベクトル (和の制約なし)\n",
        "pi_star_unconstrained = lam * invC @ r_bar\n",
        "\n",
        "# このポートフォリオベクトルの期待リターン (mu_tilde )\n",
        "expected_ret_star = r_bar @ pi_star_unconstrained\n",
        "\n",
        "# このポートフォリオベクトルの分散\n",
        "var_star_unconstrained = pi_star_unconstrained @ Cov_bar @ pi_star_unconstrained\n",
        "\n",
        "# 計算されたポートフォリオの Sharpe Ratio (リスクフリーレート0)\n",
        "# SR = Expected Return / sqrt(Variance)\n",
        "# Expected Return は mu_tilde に設定されている\n",
        "# SR = mu_tilde / sqrt(var_star_unconstrained)\n",
        "# var_star_unconstrained = (lambda * invC @ r_bar)^T @ Cov_bar @ (lambda * invC @ r_bar)\n",
        "# = lambda^2 * (invC @ r_bar)^T @ Cov_bar @ (invC @ r_bar)\n",
        "# = lambda^2 * (r_bar^T @ invC @ Cov_bar @ invC @ r_bar)\n",
        "# = lambda^2 * (r_bar^T @ invC @ r_bar) = lambda^2 * B_prime\n",
        "# SR = mu_tilde / sqrt(lambda^2 * B_prime) = mu_tilde / (abs(lambda) * sqrt(B_prime))\n",
        "# lambda = mu_tilde / B_prime なので\n",
        "# SR = mu_tilde / (abs(mu_tilde / B_prime) * sqrt(B_prime))\n",
        "# If mu_tilde > 0, SR = mu_tilde / ((mu_tilde / B_prime) * sqrt(B_prime)) = B_prime / sqrt(B_prime) = sqrt(B_prime)\n",
        "# If mu_tilde < 0, SR = mu_tilde / ((-mu_tilde / B_prime) * sqrt(B_prime)) = -B_prime / sqrt(B_prime) = -sqrt(B_prime)\n",
        "# Generally, SR = sign(mu_tilde) * sqrt(B_prime)\n",
        "\n",
        "SR_calc = np.sign(mu_tilde) * np.sqrt(B_prime) if B_prime > 0 else 0 # B_prime <= 0 の場合はSR定義が問題になる\n",
        "\n",
        "# ---- λ_min ----\n",
        "lambda_min_cov = np.min(np.linalg.eigvalsh(Cov_bar))\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. CSV 生成 – α-sweep 互換フォーマット\n",
        "# ---------------------------------------------------------------------\n",
        "cols_w   = [f\"w*_m{m}\"   for m in range(M)]\n",
        "cols_pi  = [f\"pi*_k{k}\"  for k in range(K)]\n",
        "cols_ret = [f\"cstr_ret_m{m}\" for m in range(M)]\n",
        "cols_lam = [f\"lam_m{m}\"  for m in range(M)] # ここでの lam は上記の lambda\n",
        "cols_dpi = [f\"dpi*_k{k}\" for k in range(K)]\n",
        "\n",
        "columns = ([\"alpha\", \"H_star\", \"supp_w\", \"lambda_min\",\n",
        "            \"iterations\", \"SR_rob\", \"SR_bound\"]\n",
        "           + cols_w + cols_pi + cols_ret + cols_lam + cols_dpi)\n",
        "\n",
        "# lam_m は robust 問題の各モデルに対するラグランジュ乗数だが、\n",
        "# ここでは和の制約なしMV問題の単一のラグランジュ乗数 lambda を格納する\n",
        "# フォーマット互換性のため、lambda を cols_lam の最初の要素に入れる\n",
        "lam_output = [lam] + [np.nan] * (len(cols_lam) - 1)\n",
        "\n",
        "\n",
        "row = [alpha0,\n",
        "       var_star_unconstrained,                    # H_star = 計算されたポートフォリオベクトルの分散\n",
        "       np.nan,                                  # supp_w   – 固定しないので空欄\n",
        "       lambda_min_cov,                          # lambda_min of Cov_bar\n",
        "       np.nan,                                  # iterations – 求解回数無し\n",
        "       SR_calc,                                 # SR_rob (計算されたポートフォリオのSharpe)\n",
        "       np.sqrt(B_prime) if B_prime > 0 else np.nan] # SR_bound (理論上限、sqrt(C) または sqrt(B_prime))\n",
        "row += [np.nan] * len(cols_w)                   # w*  — robust 特有 → NaN\n",
        "row += list(pi_star_unconstrained)              # pi* 4 つ (和の制約なし、目標リターン達成ベクトル)\n",
        "# 各モデル m = 0..M-1 における計算されたポートフォリオの期待リターン\n",
        "row += list(R0.T @ pi_star_unconstrained)       # 各モデル制約リターン\n",
        "row += lam_output                               # λ   — 単一の lambda を格納\n",
        "row += [np.nan] * len(cols_dpi)                 # dpi* — NaN\n",
        "\n",
        "df = pd.DataFrame([row], columns=columns)\n",
        "df.to_csv(\"alpha0_classical_mv_unconstrained_target.csv\", index=False, float_format=\"%.10g\")\n",
        "print(\"CSV written to alpha0_classical_mv_unconstrained_target.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OhBYd818_M8s",
        "outputId": "fc10eea8-fe26-4ae6-df65-21a42b9436ce"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV written to alpha0_classical_mv_unconstrained_target.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#すべて異なる場合"
      ],
      "metadata": {
        "id": "ZlWWdZBD9n0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "alpha_sweep_full_bounds_reverted_with_dpi.py\n",
        "Based on alpha_sweep_full_bounds_reverted.py, adds dpi* calculation.\n",
        "\"\"\"\n",
        "\n",
        "# ... (Imports and Global Constants remain the same) ...\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools, logging, sys\n",
        "from datetime import datetime\n",
        "import scipy.linalg as la\n",
        "from scipy.optimize import minimize, Bounds, LinearConstraint\n",
        "\n",
        "K, M         = 4, 4\n",
        "mu_tilde     = 0.03\n",
        "ALPHA_MIN    = 1e-6\n",
        "ALPHA_MAX    = 1e-5\n",
        "N_ALPHA      = 101\n",
        "ALPHA_GRID   = np.linspace(ALPHA_MIN, ALPHA_MAX, N_ALPHA)\n",
        "MAX_OPT_ITERS = 5000 # Using MAX_OPT_ITERS from reverted code context (was 10000 in original)\n",
        "tol_grad     = 1e-8\n",
        "step_size_norm_threshold = 1e-12 # Using threshold from reverted code context\n",
        "lr_init, lr_max = 0.15, 1.0 # Using lr from reverted code context\n",
        "INNER_OPT_TOL_FEAS = 1e-9\n",
        "SOLVER_FEAS_TOL    = 1e-7\n",
        "GENTOL             = 1e-9\n",
        "FINITE_DIFF_EPS    = 1e-12\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. SYNTHETIC DATA\n",
        "# ---------------------------------------------------------------------\n",
        "r_base = np.array([0.02, 0.03, 0.04, 0.05])\n",
        "Delta_A = np.array([[+1, 1, -1, -1],\n",
        "                    [+1, 1, -1, -1],\n",
        "                    [+2, -1, +2, -2],\n",
        "                    [+2, -2, +2, -2]], dtype=float)\n",
        "Delta_r_m     = Delta_A / 1000\n",
        "sigma_base    = np.array([0.20, 0.25, 0.30, 0.35])\n",
        "Delta_sigma_m = Delta_A / 100\n",
        "\n",
        "def block_corr(rho_in: float, rho_out: float) -> np.ndarray:\n",
        "    C = np.full((K, K), rho_out)\n",
        "    np.fill_diagonal(C, 1.0)\n",
        "    sectA, sectB = [0, 1], [2, 3]\n",
        "    for i in sectA:\n",
        "        for j in sectA:\n",
        "            if i != j:\n",
        "                C[i, j] = rho_in\n",
        "    for i in sectB:\n",
        "        for j in sectB:\n",
        "            if i != j:\n",
        "                C[i, j] = rho_in\n",
        "    return C\n",
        "\n",
        "C_base = block_corr(0.75, 0.50)\n",
        "tilde_C_list = [\n",
        "    block_corr(0.85, 0.40),\n",
        "    block_corr(0.65, 0.40),\n",
        "    block_corr(0.65, 0.60),\n",
        "    block_corr(0.85, 0.60),\n",
        "]\n",
        "beta_corr = 1/ALPHA_MAX\n",
        "\n",
        "\n",
        "def mix_corr(C0, C1, alpha, beta=0.5, eps=1e-4): # Copied from original context\n",
        "    C = (1 - beta * alpha) * C0 + beta * alpha * C1\n",
        "    eigval, eigvec = np.linalg.eigh(C)\n",
        "    eigval_clip = np.clip(eigval, eps, None)\n",
        "    C_spd = eigvec @ np.diag(eigval_clip) @ eigvec.T\n",
        "    D = np.sqrt(np.diag(C_spd))\n",
        "    # Check for NaN/Inf in D before division\n",
        "    if np.any(np.isnan(D)) or np.any(np.isinf(D)) or np.any(D <= 1e-10):\n",
        "        # Fallback or error handling if diagonal elements are non-positive or zero\n",
        "        # For now, return unnormalized C_spd and indicate issue with lam_min\n",
        "        return C_spd, -np.inf # Or raise error\n",
        "    D_inv = np.diag(1.0 / D)\n",
        "    C_corr = D_inv @ C_spd @ D_inv\n",
        "    # Ensure diagonal is 1 after potential numerical errors\n",
        "    np.fill_diagonal(C_corr, 1.0)\n",
        "    return C_corr, float(np.min(eigval_clip))\n",
        "\n",
        "def build_params(alpha: float): # Adapted from original robust context\n",
        "    R_th = r_base[:, None] + alpha * Delta_r_m\n",
        "    Sigma_th = np.zeros((K, K, M))\n",
        "    V_th     = np.zeros((K, K, M))\n",
        "    lambda_min_corr_log = []\n",
        "    reg_V = 1e-8; reg_S = 1e-8\n",
        "    for m in range(M):\n",
        "        sig_vec   = sigma_base + alpha * Delta_sigma_m[:, m]\n",
        "        diag_sig  = np.diag(sig_vec)\n",
        "        C_alpha, lam_min = mix_corr(C_base, tilde_C_list[m], alpha, beta=beta_corr, eps=1e-5)\n",
        "        if lam_min == -np.inf: # Handle mix_corr failure\n",
        "             raise ValueError(f\"mix_corr failed for alpha={alpha}, m={m}\")\n",
        "        lambda_min_corr_log.append(lam_min)\n",
        "        V_m = diag_sig @ C_alpha @ diag_sig\n",
        "        min_eig_Vm = np.min(np.linalg.eigvalsh(V_m))\n",
        "        if min_eig_Vm <= reg_V: V_m += np.eye(K) * (abs(min_eig_Vm) + reg_V)\n",
        "        V_th[:, :, m] = V_m\n",
        "        Sigma_th[:, :, m] = V_m + np.outer(R_th[:, m], R_th[:, m])\n",
        "        min_eig_Sm = np.min(np.linalg.eigvalsh(Sigma_th[:, :, m]))\n",
        "        if min_eig_Sm <= reg_S: Sigma_th[:, :, m] += np.eye(K) * (abs(min_eig_Sm) + reg_S)\n",
        "    lambda_min_for_csv = float(min(lambda_min_corr_log)) if lambda_min_corr_log else np.nan\n",
        "    # Original robust code had a rank check on R_th, might be needed depending on K,M\n",
        "    if np.linalg.matrix_rank(R_th, tol=1e-12) < M and K >= M:\n",
        "      raise RuntimeError('R_th is not full column rank')\n",
        "    return R_th, Sigma_th, V_th, lambda_min_for_csv\n",
        "\n",
        "# --- UTILITY FUNCTIONS (proj_simplex, Y0, X_piY) ---\n",
        "# (Assumed identical to previous correct versions, omitted for brevity)\n",
        "def proj_simplex(v: np.ndarray) -> np.ndarray:\n",
        "    v = np.asarray(v, float); u = np.sort(v)[::-1]; cssv = np.cumsum(u) - 1\n",
        "    if (v >= 0).all() and np.isclose(v.sum(), 1.0, atol=1e-9): return v\n",
        "    try:\n",
        "        idx_rho = np.where(u * (np.arange(len(u)) + 1) > cssv)[0]\n",
        "        rho = idx_rho[-1] if len(idx_rho) > 0 else len(u) - 1\n",
        "        theta = cssv[rho] / (rho + 1); return np.maximum(v - theta, 0.0)\n",
        "    except IndexError: return np.ones_like(v) / len(v)\n",
        "\n",
        "def calculate_Y0(R_trial, Sigma_list_trial, mu_tilde_val, k_assets, m_models, rng_y0_pert):\n",
        "    pi_avg_r = np.mean(R_trial, axis=1)\n",
        "    if np.linalg.norm(pi_avg_r) > 1e-6: pi_initial_guess = pi_avg_r / np.linalg.norm(pi_avg_r)\n",
        "    else: pi_initial_guess = np.ones(k_assets) / np.sqrt(k_assets)\n",
        "    max_tries_feas = 10; found_feasible_pi = False\n",
        "    for i_try in range(max_tries_feas):\n",
        "        min_constr_val = np.min(R_trial.T @ pi_initial_guess)\n",
        "        if min_constr_val >= mu_tilde_val - SOLVER_FEAS_TOL :\n",
        "             if min_constr_val < mu_tilde_val: pi_initial_guess *= (mu_tilde_val / (min_constr_val if abs(min_constr_val) > 1e-9 else 1e-9)) * 1.01\n",
        "             found_feasible_pi = True; break\n",
        "        elif min_constr_val > 0 : pi_initial_guess *= (mu_tilde_val / min_constr_val) * (1.1 + 0.1 * i_try)\n",
        "        else:\n",
        "            pi_initial_guess += rng_y0_pert.normal(0, 0.1, size=k_assets)\n",
        "            if np.linalg.norm(pi_initial_guess) > 1e-6: pi_initial_guess /= np.linalg.norm(pi_initial_guess)\n",
        "            else: pi_initial_guess = rng_y0_pert.random(k_assets); pi_initial_guess /= (np.linalg.norm(pi_initial_guess) if np.linalg.norm(pi_initial_guess) > 1e-6 else 1)\n",
        "    if not found_feasible_pi:\n",
        "        try:\n",
        "            pi_lstsq = np.linalg.lstsq(R_trial.T, np.full(m_models, mu_tilde_val), rcond=None)[0]\n",
        "            if np.min(R_trial.T @ pi_lstsq) >= mu_tilde_val - SOLVER_FEAS_TOL: pi_initial_guess = pi_lstsq\n",
        "            else: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "        except np.linalg.LinAlgError: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "    t_initial_guess = 0.0\n",
        "    for m in range(m_models): t_initial_guess = max(t_initial_guess, pi_initial_guess @ Sigma_list_trial[:,:,m] @ pi_initial_guess)\n",
        "    t_initial_guess = max(1e-6, t_initial_guess)\n",
        "    x_initial = np.concatenate([pi_initial_guess, [t_initial_guess]])\n",
        "    func = lambda x: x[-1]; cons = []\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, Sm=Sigma_list_trial[:,:,m]: x[-1] - x[:-1] @ Sm @ x[:-1]})\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, rm=R_trial[:,m]: x[:-1] @ rm - mu_tilde_val})\n",
        "    bounds = [(-np.inf, np.inf)] * k_assets + [(1e-8, np.inf)]\n",
        "    opt_res_Y0 = minimize(func, x_initial, method='SLSQP', bounds=bounds, constraints=cons, options={'ftol': 1e-8, 'disp': False, 'maxiter': 1000})\n",
        "    pi_Y = None; Y0_val = np.nan\n",
        "    if opt_res_Y0.success:\n",
        "        pi_sol, t_sol = opt_res_Y0.x[:-1], opt_res_Y0.x[-1]; feasible = True\n",
        "        min_ret_check = np.min(R_trial.T @ pi_sol)\n",
        "        max_quad_check = np.max([pi_sol @ Sigma_list_trial[:,:,m] @ pi_sol for m in range(m_models)])\n",
        "        if min_ret_check < mu_tilde_val - SOLVER_FEAS_TOL: feasible = False\n",
        "        if abs(t_sol - max_quad_check) > SOLVER_FEAS_TOL * (1 + abs(t_sol)) + 1e-7 : feasible = False\n",
        "        if feasible: pi_Y = pi_sol; Y0_val = t_sol\n",
        "    return pi_Y, Y0_val\n",
        "\n",
        "def calculate_X_pi_Y(pi_Y, R_trial, Sigma_list_trial, V_list_trial, k_assets, m_models):\n",
        "    if pi_Y is None: return np.nan\n",
        "    v_m_vec = np.array([pi_Y @ V_list_trial[:,:,m] @ pi_Y for m in range(m_models)])\n",
        "    a_m_vec = R_trial.T @ pi_Y\n",
        "    Q_mat = np.outer(a_m_vec, a_m_vec)\n",
        "    c_vec = v_m_vec + a_m_vec**2\n",
        "    obj_func = lambda w: w @ Q_mat @ w - c_vec @ w\n",
        "    jac_func = lambda w: 2 * Q_mat @ w - c_vec\n",
        "    bounds_w = Bounds(np.zeros(m_models), np.full(m_models, np.inf))\n",
        "    constraints_w = LinearConstraint(np.ones((1, m_models)), [1.0], [1.0])\n",
        "    w_initial = np.ones(m_models) / m_models\n",
        "    qp_res = minimize(obj_func, w_initial, method='SLSQP', jac=jac_func,\n",
        "                      bounds=bounds_w, constraints=constraints_w,\n",
        "                      options={'ftol': 1e-9, 'disp': False})\n",
        "    if qp_res.success:\n",
        "        w_opt_for_X = qp_res.x; w_opt_for_X = np.maximum(0, w_opt_for_X); w_opt_for_X /= np.sum(w_opt_for_X)\n",
        "        var_a_m = w_opt_for_X @ (a_m_vec**2) - (w_opt_for_X @ a_m_vec)**2\n",
        "        X_piY_val = w_opt_for_X @ v_m_vec + var_a_m\n",
        "        return max(0, X_piY_val)\n",
        "    else: return np.nan\n",
        "\n",
        "# --- INNER MINIMISATION (Using robust version) ---\n",
        "def inner_opt(w, R, Sigma, lam_tol=-1e-13, rank_scale=1e-10):\n",
        "    k_assets, m_models = R.shape; rank_tol = rank_scale * np.linalg.norm(R); Ex = R @ w\n",
        "    Sigma_w_bar = np.sum(np.fromiter((w[m] * Sigma[:, :, m] for m in range(m_models)), dtype=object))\n",
        "    Vw = Sigma_w_bar - np.outer(Ex, Ex)\n",
        "    try: min_eig_Vw = np.min(np.linalg.eigvalsh(Vw))\n",
        "    except np.linalg.LinAlgError: return None, np.inf, Ex, None, None\n",
        "    if min_eig_Vw <= 1e-10: Vw += np.eye(k_assets) * (abs(min_eig_Vw) + 1e-8)\n",
        "    try: Vinv = np.linalg.inv(Vw)\n",
        "    except np.linalg.LinAlgError: return None, np.inf, Ex, None, None\n",
        "    best_val = np.inf; best_pi = None; best_lam = None; best_subset = None\n",
        "    for s in range(1, m_models + 1):\n",
        "        for subset in itertools.combinations(range(m_models), s):\n",
        "            subset_indices = list(subset); A = R[:, subset_indices].T\n",
        "            if np.linalg.matrix_rank(A, tol=rank_tol) < s: continue\n",
        "            Mmat = A @ Vinv @ A.T\n",
        "            try: cond_Mmat = np.linalg.cond(Mmat)\n",
        "            except np.linalg.LinAlgError: continue\n",
        "            if cond_Mmat > 1e8: continue\n",
        "            try: lam, residuals, rank, s_val = np.linalg.lstsq(Mmat, mu_tilde * np.ones(s), rcond=None)\n",
        "            except np.linalg.LinAlgError: continue\n",
        "            if rank < s or (residuals.size > 0 and residuals[0] > 1e-6): continue\n",
        "            if np.any(lam < lam_tol): continue\n",
        "            pi = Vinv @ A.T @ lam\n",
        "            if np.min(R.T @ pi) < mu_tilde - INNER_OPT_TOL_FEAS: continue\n",
        "            val = pi @ (Sigma_w_bar - np.outer(Ex, Ex)) @ pi # Use original Vw definition for value\n",
        "            if val < best_val - GENTOL * (1 + abs(best_val)): best_val,best_pi,best_lam,best_subset = val,pi,lam,subset\n",
        "    if best_pi is None: return None, np.inf, Ex, None, None\n",
        "    return best_pi, best_val, Ex, best_lam, best_subset\n",
        "\n",
        "# --- H_and_grad, optimise_outer_reverted (Using original optimisation logic) ---\n",
        "# Need to copy the original H_and_grad and optimise_outer from the 'reverted' context\n",
        "# Assuming they are named H_and_grad_reverted and optimise_outer_reverted\n",
        "# H_and_grad_reverted would call the original inner_opt_reverted\n",
        "# This requires providing the original inner_opt logic. Let's assume it's available.\n",
        "\n",
        "# Placeholder for the original inner_opt logic (needs to be provided from the original script)\n",
        "def inner_opt_reverted(w, R, Sigma, tol_feas=1e-9, lam_tol=-1e-13, rank_scale=1e-10):\n",
        "    # *** This function needs the exact code from the original alpha_sweep_K4M4_SR.py ***\n",
        "    # *** For now, using the robust one as a placeholder - REPLACE THIS ***\n",
        "    # return inner_opt(w, R, Sigma, lam_tol=lam_tol, rank_scale=rank_scale) # Placeholder\n",
        "\n",
        "    # --- Start of copied original inner_opt logic ---\n",
        "    rank_tol = rank_scale * np.linalg.norm(R)\n",
        "    Ex = R @ w\n",
        "    # Use np.sum with generator directly as in original\n",
        "    Vw = sum(w[m] * Sigma[:, :, m] for m in range(M)) - np.outer(Ex, Ex)\n",
        "    try:\n",
        "        Vinv = np.linalg.inv(Vw)\n",
        "    except np.linalg.LinAlgError:\n",
        "        return None, np.inf, Ex, None, None\n",
        "\n",
        "    best_val = np.inf\n",
        "    best_pi = best_lam = best_subset = None\n",
        "\n",
        "    for s in range(1, M + 1):\n",
        "        for subset in itertools.combinations(range(M), s):\n",
        "            A = R[:, subset].T\n",
        "            if np.linalg.matrix_rank(A, tol=rank_tol) < s: continue\n",
        "            Mmat = A @ Vinv @ A.T\n",
        "            # Original check might have been slightly different, e.g., no condition number check\n",
        "            if np.linalg.matrix_rank(Mmat, tol=rank_tol) < s: continue\n",
        "            try:\n",
        "                lam = np.linalg.solve(Mmat, mu_tilde * np.ones(s)) # Original used solve\n",
        "            except np.linalg.LinAlgError:\n",
        "                 continue # Handle potential solve failure\n",
        "\n",
        "            if np.any(lam < lam_tol): continue\n",
        "            pi = Vinv @ A.T @ lam\n",
        "            # Original check used global tol_feas implicitly? Ensure it's correct.\n",
        "            if np.any(R.T @ pi < mu_tilde - tol_feas): continue\n",
        "            val = pi @ Vw @ pi\n",
        "            # Original comparison tolerance\n",
        "            if val + 1e-12 < best_val:\n",
        "                best_val, best_pi, best_lam, best_subset = val, pi, lam, subset\n",
        "\n",
        "    if best_pi is None:\n",
        "        return None, np.inf, Ex, None, None\n",
        "    return best_pi, best_val, Ex, best_lam, best_subset\n",
        "    # --- End of copied original inner_opt logic ---\n",
        "\n",
        "\n",
        "def H_and_grad_reverted(w, R, Sigma):\n",
        "    # Calls the reverted inner_opt\n",
        "    pi, val, Ex, lam, subset = inner_opt_reverted(w, R, Sigma, tol_feas=INNER_OPT_TOL_FEAS) # Pass tol_feas explicitly\n",
        "    if val == np.inf or pi is None: # Added pi is None check\n",
        "        return val, None, pi, lam, subset\n",
        "    # Grad calculation is standard\n",
        "    grad = np.array([pi @ Sigma[:, :, m] @ pi - 2 * (pi @ R[:, m]) * (pi @ Ex) for m in range(M)])\n",
        "    return val, grad, pi, lam, subset\n",
        "\n",
        "def optimise_outer_reverted(R, Sigma, *, start=None, seed=None):\n",
        "    # Uses H_and_grad_reverted, rest of logic is from original alpha_sweep_K4M4_SR.py\n",
        "    if start is None:\n",
        "        rng = np.random.default_rng(seed) if seed is not None else np.random.default_rng()\n",
        "        w = proj_simplex(rng.random(M))\n",
        "    else: w = proj_simplex(start)\n",
        "\n",
        "    # Initial call using reverted H_and_grad\n",
        "    val, g, pi, lam, subset = H_and_grad_reverted(w, R, Sigma)\n",
        "    if g is None: return np.nan, None, None, None, None, 0\n",
        "\n",
        "    best = (val, w.copy(), pi, lam, subset)\n",
        "    lr   = lr_init # Use lr_init from original context\n",
        "    g_prev, w_prev = g.copy(), w.copy()\n",
        "\n",
        "    # Use MAX_OPT_ITERS from original context (e.g., 10000)\n",
        "    current_max_opt_iters = 10000 # Match original script context\n",
        "\n",
        "    for it in range(1, current_max_opt_iters + 1): # Use original MAX_OPT_ITERS\n",
        "        proj_grad = w - proj_simplex(w - g) # Check KKT condition\n",
        "        # Use tol_grad from original context\n",
        "        if np.linalg.norm(proj_grad) < tol_grad: break\n",
        "\n",
        "        if it > 1:\n",
        "            dw, dg = w - w_prev, g - g_prev; denom = dg @ dg\n",
        "            if denom > 1e-12:\n",
        "                gamma_bb = (dw @ dg) / denom\n",
        "                if gamma_bb > 0.0:\n",
        "                    # Use lr_max from original context\n",
        "                    lr = np.clip(gamma_bb, 1e-4, lr_max)\n",
        "\n",
        "        lr_curr = lr; accept  = False\n",
        "        # Line search parameters might differ slightly, use original logic's values/checks\n",
        "        while lr_curr >= 1e-6: # Original line search lower bound? Assume 1e-6\n",
        "            w_trial = proj_simplex(w + lr_curr * g)\n",
        "            # Use step_size_norm_threshold from original context\n",
        "            if np.linalg.norm(w_trial - w) < step_size_norm_threshold:\n",
        "                lr_curr = 0.0; break\n",
        "            # Call reverted H_and_grad\n",
        "            val_t, g_t, pi_t, lam_t, subset_t = H_and_grad_reverted(w_trial, R, Sigma)\n",
        "\n",
        "            # Check for failure in H_and_grad_reverted\n",
        "            if g_t is None:\n",
        "                 lr_curr *= 0.5; continue\n",
        "\n",
        "            # Original Armijo check tolerance\n",
        "            if val_t >= val - 1e-12:\n",
        "                w_prev, g_prev = w.copy(), g.copy(); w, val, g = w_trial, val_t, g_t\n",
        "                pi, lam, subset = pi_t, lam_t, subset_t\n",
        "                # Original best update check (might have used different tolerance)\n",
        "                if val > best[0]: # Assume simple > check was used originally\n",
        "                    best = (val, w.copy(), pi, lam, subset)\n",
        "                # Use original lr update logic\n",
        "                lr = min(lr_curr * 1.2, lr_max)\n",
        "                accept = True; break\n",
        "            lr_curr *= 0.5\n",
        "        if not accept: break\n",
        "    return (*best, it) # Return best found solution and iteration count\n",
        "\n",
        "# --- CALCULATE BOUNDS AND SR ---\n",
        "def calculate_bounds_and_sr(pi_star, w_star, H_star_val, R_th, Sigma_th, V_th):\n",
        "    # (Identical to previous robust version)\n",
        "    SR_rob_val, B_U1_val, B_U2_val = np.nan, np.nan, np.nan\n",
        "    if pi_star is None or w_star is None or np.isnan(H_star_val): return SR_rob_val, B_U1_val, B_U2_val\n",
        "    r_bar_ws = R_th @ w_star; numerator_sr = pi_star @ r_bar_ws\n",
        "    denominator_sr_sq = H_star_val\n",
        "    if denominator_sr_sq > 1e-12: SR_rob_val = numerator_sr / np.sqrt(denominator_sr_sq)\n",
        "    elif abs(numerator_sr) < GENTOL: SR_rob_val = 0.0\n",
        "    Sigma_w_star_bar = np.sum(np.fromiter((w_star[m] * Sigma_th[:, :, m] for m in range(M)), dtype=object))\n",
        "    Vw_star_check = Sigma_w_star_bar - np.outer(r_bar_ws, r_bar_ws)\n",
        "    try: Vw_star_inv = np.linalg.inv(Vw_star_check + np.eye(K)*1e-10); s_w_star_num = r_bar_ws @ Vw_star_inv @ r_bar_ws\n",
        "    except np.linalg.LinAlgError: B_U1_val = np.nan; s_w_star_num=-1 # Assign default for calculation below\n",
        "    else: # Only calculate if inverse succeeded\n",
        "        if s_w_star_num < -GENTOL: s_w_star_num = 0\n",
        "        B_U1_val = np.sqrt(s_w_star_num)\n",
        "    rho_m_vals = np.zeros(M); all_rho_m_ok = True\n",
        "    for m in range(M):\n",
        "        try: Sigma_m_inv = np.linalg.inv(Sigma_th[:,:,m] + np.eye(K)*1e-10); rho_m_vals[m] = R_th[:,m] @ Sigma_m_inv @ R_th[:,m]\n",
        "        except np.linalg.LinAlgError: all_rho_m_ok = False; break\n",
        "    if all_rho_m_ok:\n",
        "        rho_max_val = np.max(rho_m_vals); rho_max_val = min(rho_max_val, 1.0 - 1e-12)\n",
        "        if rho_max_val < 0: B_U2_val = np.nan\n",
        "        else: B_U2_val = np.sqrt(rho_max_val / (1.0 - rho_max_val))\n",
        "    else: B_U2_val = np.nan\n",
        "    return SR_rob_val, B_U1_val, B_U2_val\n",
        "\n",
        "# --- FINITE DIFFERENCE HELPER ---\n",
        "def finite_diff_vec(v_p, v_m, h, length):\n",
        "    # (Identical to previous)\n",
        "    if v_p is None or v_m is None or h is None or np.isnan(h) or abs(h) < FINITE_DIFF_EPS: return np.full(length, np.nan)\n",
        "    # Ensure h is not zero before dividing\n",
        "    actual_h = h if abs(h) > FINITE_DIFF_EPS else np.sign(h)*FINITE_DIFF_EPS if h!=0 else FINITE_DIFF_EPS\n",
        "    return (v_p - v_m) / (2 * actual_h) # Use 2*h for central difference\n",
        "\n",
        "# --- α-SWEEP MAIN FUNCTION (with reverted opt logic and dpi*) ---\n",
        "def run_alpha_sweep_full_bounds_reverted_with_dpi(csv_path=\"alpha_sweep_full_bounds_reverted_dpi.csv\", *, seed_outer=None):\n",
        "    log = logging.getLogger(\"sweep_revert_dpi\")\n",
        "    log.propagate = False\n",
        "    log.setLevel(logging.INFO)\n",
        "    if not log.handlers: log.addHandler(logging.StreamHandler(sys.stdout))\n",
        "\n",
        "    col_w = [f\"w*_m{m}\" for m in range(M)]; col_pi = [f\"pi*_k{k}\" for k in range(K)]\n",
        "    col_ret = [f\"cstr_ret_m{m}\" for m in range(M)]; col_lam = [f\"lam_m{m}\" for m in range(M)]\n",
        "    col_dpi = [f\"dpi*_k{k}\" for k in range(K)]\n",
        "    columns = ([\"alpha\", \"H_star\", \"supp_w\", \"lambda_min_corr\", \"iterations\", \"SR_rob\",\n",
        "                \"SR_Bound_Sw\", \"SR_Bound_rho_max\", \"SR_Bound_Y0\", \"SR_Bound_XpiY\",\n",
        "                \"Y0_val\", \"XpiY_val\"] + col_w + col_pi + col_ret + col_lam + col_dpi)\n",
        "    rows, cache = [], {}\n",
        "    rng_y0 = np.random.default_rng(seed_outer + 1 if seed_outer is not None else 43)\n",
        "    t0 = datetime.now(); y0_fail_count = 0; xpiy_fail_count = 0; opt_fail_count = 0\n",
        "\n",
        "    log.info(f\"========== α-Sweep Full Bounds START (N_ALPHA={N_ALPHA}, Reverted Opt Logic, with dpi*) ==========\")\n",
        "\n",
        "    # --- Define get function for caching ---\n",
        "    def get(a, seed_for_opt):\n",
        "        cache_key = (a, seed_for_opt)\n",
        "        if cache_key not in cache:\n",
        "            try:\n",
        "                R_a, Sigma_a, V_a, lam_min_a = build_params(a)\n",
        "                H_star_a, w_star_a, pi_star_a, lam_star_a, subset_a, iters_a = optimise_outer_reverted(\n",
        "                    R_a, Sigma_a, seed=seed_for_opt)\n",
        "                if pi_star_a is None or w_star_a is None or np.isnan(H_star_a): raise ValueError(\"Optimise_outer_reverted returned None/NaN\")\n",
        "                cache[cache_key] = dict(H_star=H_star_a, w_star=w_star_a, pi_star=pi_star_a,\n",
        "                                    lam_star=lam_star_a, subset=subset_a, R=R_a, Sigma=Sigma_a, V=V_a,\n",
        "                                    lambda_min_corr=lam_min_a, iters=iters_a)\n",
        "            except (RuntimeError, ValueError, np.linalg.LinAlgError, TypeError) as e:\n",
        "                # log.warning(f\"Get failed for alpha={a}. Error: {e}\")\n",
        "                cache[cache_key] = None\n",
        "        return cache[cache_key]\n",
        "    # --- End of get function ---\n",
        "\n",
        "    for idx, alpha in enumerate(ALPHA_GRID):\n",
        "        if (idx * 100 // N_ALPHA) > ((idx - 1) * 100 // N_ALPHA):\n",
        "             log.info(f\"Progress: {idx * 100 / N_ALPHA:.0f}% (α = {alpha:.5f})\")\n",
        "\n",
        "        current_seed = seed_outer # Use same seed across alpha if provided, else None\n",
        "        res_c = get(alpha, current_seed)\n",
        "\n",
        "        if res_c is None:\n",
        "            opt_fail_count += 1 # Increment failure count here based on get() result\n",
        "            continue\n",
        "\n",
        "        H_star, w_star, pi_star, lam_star, subset, R_th, Sigma_th, V_th, lambda_min_val, iters = \\\n",
        "            res_c[\"H_star\"], res_c[\"w_star\"], res_c[\"pi_star\"], res_c[\"lam_star\"], res_c[\"subset\"], \\\n",
        "            res_c[\"R\"], res_c[\"Sigma\"], res_c[\"V\"], res_c[\"lambda_min_corr\"], res_c[\"iters\"]\n",
        "\n",
        "        SR_rob, B_U1, B_U2 = calculate_bounds_and_sr(pi_star, w_star, H_star, R_th, Sigma_th, V_th)\n",
        "        pi_Y, Y0_val = calculate_Y0(R_th, Sigma_th, mu_tilde, K, M, rng_y0)\n",
        "        if pi_Y is None or np.isnan(Y0_val): y0_fail_count += 1\n",
        "        XpiY_val = calculate_X_pi_Y(pi_Y, R_th, Sigma_th, V_th, K, M)\n",
        "        if pi_Y is not None and np.isnan(XpiY_val): xpiy_fail_count += 1\n",
        "        B_L1 = mu_tilde / np.sqrt(Y0_val) if Y0_val is not None and not np.isnan(Y0_val) and Y0_val > 1e-12 else np.nan\n",
        "        B_L2 = mu_tilde / np.sqrt(XpiY_val) if XpiY_val is not None and not np.isnan(XpiY_val) and XpiY_val > 1e-12 else np.nan\n",
        "\n",
        "        # --- Calculate dpi* (Finite Difference) using get ---\n",
        "        dpi_star = np.full(K, np.nan)\n",
        "        prev_alpha = ALPHA_GRID[idx - 1] if idx > 0 else None\n",
        "        next_alpha = ALPHA_GRID[idx + 1] if idx < N_ALPHA - 1 else None\n",
        "        h = np.nan\n",
        "        pi_p, pi_m = None, None\n",
        "\n",
        "        if prev_alpha is not None and next_alpha is not None:\n",
        "            h = min(alpha - prev_alpha, next_alpha - alpha)\n",
        "            if h < FINITE_DIFF_EPS: h = FINITE_DIFF_EPS # Ensure h is not too small\n",
        "            res_p = get(alpha + h, current_seed)\n",
        "            res_m = get(alpha - h, current_seed)\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / (2*h)\n",
        "\n",
        "        elif prev_alpha is None and next_alpha is not None: # Forward difference\n",
        "            h = next_alpha - alpha\n",
        "            if h >= FINITE_DIFF_EPS:\n",
        "                res_p = get(next_alpha, current_seed)\n",
        "                if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "                pi_m = pi_star\n",
        "                if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "\n",
        "        elif next_alpha is None and prev_alpha is not None: # Backward difference\n",
        "            h = alpha - prev_alpha\n",
        "            if h >= FINITE_DIFF_EPS:\n",
        "                res_m = get(prev_alpha, current_seed)\n",
        "                if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "                pi_p = pi_star\n",
        "                if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "        # Note: Central difference is generally preferred if possible.\n",
        "\n",
        "        # --- Format other outputs ---\n",
        "        cstr_ret = R_th.T @ pi_star if pi_star is not None else np.full(M, np.nan)\n",
        "        lam_vec = np.zeros(M)\n",
        "        if lam_star is not None and subset is not None:\n",
        "            try: # Add try-except for safety\n",
        "                subset_indices = tuple(map(int, subset))\n",
        "                if len(lam_star) == len(subset_indices):\n",
        "                    for j, m_idx in enumerate(subset_indices):\n",
        "                        if 0 <= m_idx < M: lam_vec[m_idx] = lam_star[j]\n",
        "            except (TypeError, IndexError): # Handle if subset is not iterable or index out of bounds\n",
        "                pass # Keep lam_vec as zeros\n",
        "\n",
        "        # --- Append row ---\n",
        "        row_data = {\"alpha\": alpha, \"H_star\": H_star, \"supp_w\": int((w_star > 1e-6).sum()),\n",
        "                    \"lambda_min_corr\": lambda_min_val, \"iterations\": iters, \"SR_rob\": SR_rob,\n",
        "                    \"SR_Bound_Sw\": B_U1, \"SR_Bound_rho_max\": B_U2, \"SR_Bound_Y0\": B_L1, \"SR_Bound_XpiY\": B_L2,\n",
        "                    \"Y0_val\": Y0_val, \"XpiY_val\": XpiY_val}\n",
        "        row_data.update({f\"w*_m{m}\": w_star[m] for m in range(M)})\n",
        "        row_data.update({f\"pi*_k{k}\": pi_star[k] for k in range(K)})\n",
        "        row_data.update({f\"cstr_ret_m{m}\": cstr_ret[m] for m in range(M)})\n",
        "        row_data.update({f\"lam_m{m}\": lam_vec[m] for m in range(M)})\n",
        "        row_data.update({f\"dpi*_k{k}\": dpi_star[k] for k in range(K)}) # Add calculated dpi_star\n",
        "        rows.append(row_data)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "    df.to_csv(csv_path, index=False, float_format=\"%.10g\")\n",
        "    log.info(f\"CSV written to {csv_path}  (elapsed {(datetime.now() - t0).total_seconds():.1f}s)\")\n",
        "    log.info(f\"Total Opt Fails: {opt_fail_count}, Y0 Fails: {y0_fail_count}, XpiY Fails: {xpiy_fail_count}\")\n",
        "    return df\n",
        "\n",
        "# --- Need to define optimise_outer_reverted and H_and_grad_reverted using original logic ---\n",
        "# Assuming these are defined elsewhere in the execution environment based on the original script.\n",
        "# If not, they need to be copied/pasted here.\n",
        "\n",
        "# --- MAIN EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "     # Make sure optimise_outer_reverted and H_and_grad_reverted are defined correctly based on the original script\n",
        "     # that produced the successful results before adding bounds.\n",
        "     # Example call:\n",
        "     run_alpha_sweep_full_bounds_reverted_with_dpi(seed_outer=123)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xcAjv8R9nbY",
        "outputId": "fe497d04-2d40-4b49-a3d5-a8d10293cb43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "========== α-Sweep Full Bounds START (N_ALPHA=101, Reverted Opt Logic, with dpi*) ==========\n",
            "Progress: 0% (α = 0.00000)\n",
            "Progress: 2% (α = 0.00000)\n",
            "Progress: 3% (α = 0.00000)\n",
            "Progress: 4% (α = 0.00000)\n",
            "Progress: 5% (α = 0.00000)\n",
            "Progress: 6% (α = 0.00000)\n",
            "Progress: 7% (α = 0.00000)\n",
            "Progress: 8% (α = 0.00000)\n",
            "Progress: 9% (α = 0.00000)\n",
            "Progress: 10% (α = 0.00000)\n",
            "Progress: 11% (α = 0.00000)\n",
            "Progress: 12% (α = 0.00000)\n",
            "Progress: 13% (α = 0.00000)\n",
            "Progress: 14% (α = 0.00000)\n",
            "Progress: 15% (α = 0.00000)\n",
            "Progress: 16% (α = 0.00000)\n",
            "Progress: 17% (α = 0.00000)\n",
            "Progress: 18% (α = 0.00000)\n",
            "Progress: 19% (α = 0.00000)\n",
            "Progress: 20% (α = 0.00000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "w2Nt37NKB04h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$r^m$のみが異なる場合"
      ],
      "metadata": {
        "id": "QdlhGX9CBxiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "halfpair_sweep_exact_qp_bounds_dpi.py\n",
        "- Robust MVP (V fixed, r varies) α-sweep using EXACT inner QP solve.\n",
        "- Calculates bounds from Thm 2, Thm 6, Thm 8 and dpi*.\n",
        "\"\"\"\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 0. IMPORTS & CONSTANTS\n",
        "# ---------------------------------------------------------------------\n",
        "import numpy as np\n",
        "import itertools, math, logging, sys\n",
        "import scipy.linalg as la\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from scipy.optimize import minimize, Bounds, LinearConstraint\n",
        "\n",
        "K, M         = 4, 4\n",
        "mu_tilde     = 0.03\n",
        "\n",
        "\n",
        "INNER_OPT_TOL_FEAS = 1e-9\n",
        "SOLVER_FEAS_TOL    = 1e-7\n",
        "GENTOL             = 1e-9\n",
        "FINITE_DIFF_EPS    = 1e-12\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. SYNTHETIC DATA & FIXED PARAMETERS\n",
        "# ---------------------------------------------------------------------\n",
        "r_base = np.array([0.02, 0.03, 0.04, 0.05])\n",
        "Delta_A = np.array([[+1, 1, -1, -1],[+1, 1, -1, -1],\n",
        "                    [+2, -1, +2, -2],[+2, -2, +2, -2]], dtype=float)\n",
        "Delta_r_m = Delta_A / 1000\n",
        "sigma_base = np.array([0.20, 0.25, 0.30, 0.35])\n",
        "\n",
        "def block_corr(rho_in: float, rho_out: float) -> np.ndarray:\n",
        "    C = np.full((K, K), rho_out); np.fill_diagonal(C, 1.0)\n",
        "    sectA, sectB = [0, 1], [2, 3];\n",
        "    for i in sectA:\n",
        "        for j in sectA:\n",
        "            if i != j: C[i, j] = rho_in\n",
        "    for i in sectB:\n",
        "        for j in sectB:\n",
        "            if i != j: C[i, j] = rho_in\n",
        "    return C\n",
        "\n",
        "C_base = block_corr(0.75, 0.50)\n",
        "Vbar   = np.diag(sigma_base) @ C_base @ np.diag(sigma_base)\n",
        "min_eig_Vbar = np.min(np.linalg.eigvalsh(Vbar))\n",
        "if min_eig_Vbar <= 1e-9: Vbar += np.eye(K) * (abs(min_eig_Vbar) + 1e-8)\n",
        "lambda_min_Vbar = float(np.min(np.linalg.eigvalsh(Vbar)))\n",
        "\n",
        "def get_params_r_only(alpha):\n",
        "    R_th = r_base[:, None] + alpha * Delta_r_m\n",
        "    Sigma_th = np.zeros((K, K, M))\n",
        "    V_th = np.repeat(Vbar[:, :, np.newaxis], M, axis=2) # V is fixed\n",
        "    for m in range(M):\n",
        "         Sigma_th[:, :, m] = Vbar + np.outer(R_th[:, m], R_th[:, m])\n",
        "         min_eig_Sm = np.min(np.linalg.eigvalsh(Sigma_th[:, :, m]))\n",
        "         if min_eig_Sm <= 1e-9: Sigma_th[:, :, m] += np.eye(K) * (abs(min_eig_Sm) + 1e-8)\n",
        "    return R_th, Sigma_th, V_th\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. UTILITY FUNCTIONS (proj_simplex, Y0, X_piY)\n",
        "# ---------------------------------------------------------------------\n",
        "# (Identical to previous correct versions, omitted for brevity)\n",
        "def proj_simplex(v: np.ndarray) -> np.ndarray:\n",
        "    v = np.asarray(v, float); u = np.sort(v)[::-1]; cssv = np.cumsum(u) - 1\n",
        "    if (v >= 0).all() and np.isclose(v.sum(), 1.0, atol=1e-9): return v\n",
        "    try:\n",
        "        idx_rho = np.where(u * (np.arange(len(u)) + 1) > cssv)[0]\n",
        "        rho = idx_rho[-1] if len(idx_rho) > 0 else len(u) - 1\n",
        "        theta = cssv[rho] / (rho + 1); return np.maximum(v - theta, 0.0)\n",
        "    except IndexError: return np.ones_like(v) / len(v)\n",
        "\n",
        "def calculate_Y0(R_trial, Sigma_list_trial, mu_tilde_val, k_assets, m_models, rng_y0_pert):\n",
        "    pi_avg_r = np.mean(R_trial, axis=1)\n",
        "    if np.linalg.norm(pi_avg_r) > 1e-6: pi_initial_guess = pi_avg_r / np.linalg.norm(pi_avg_r)\n",
        "    else: pi_initial_guess = np.ones(k_assets) / np.sqrt(k_assets)\n",
        "    max_tries_feas = 10; found_feasible_pi = False\n",
        "    for i_try in range(max_tries_feas):\n",
        "        min_constr_val = np.min(R_trial.T @ pi_initial_guess)\n",
        "        if min_constr_val >= mu_tilde_val - SOLVER_FEAS_TOL :\n",
        "             if min_constr_val < mu_tilde_val: pi_initial_guess *= (mu_tilde_val / (min_constr_val if abs(min_constr_val) > 1e-9 else 1e-9)) * 1.01\n",
        "             found_feasible_pi = True; break\n",
        "        elif min_constr_val > 0 : pi_initial_guess *= (mu_tilde_val / min_constr_val) * (1.1 + 0.1 * i_try)\n",
        "        else:\n",
        "            pi_initial_guess += rng_y0_pert.normal(0, 0.1, size=k_assets)\n",
        "            if np.linalg.norm(pi_initial_guess) > 1e-6: pi_initial_guess /= np.linalg.norm(pi_initial_guess)\n",
        "            else: pi_initial_guess = rng_y0_pert.random(k_assets); pi_initial_guess /= (np.linalg.norm(pi_initial_guess) if np.linalg.norm(pi_initial_guess) > 1e-6 else 1)\n",
        "    if not found_feasible_pi:\n",
        "        try:\n",
        "            pi_lstsq = np.linalg.lstsq(R_trial.T, np.full(m_models, mu_tilde_val), rcond=None)[0]\n",
        "            if np.min(R_trial.T @ pi_lstsq) >= mu_tilde_val - SOLVER_FEAS_TOL: pi_initial_guess = pi_lstsq\n",
        "            else: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "        except np.linalg.LinAlgError: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "    t_initial_guess = 0.0\n",
        "    for m in range(m_models): t_initial_guess = max(t_initial_guess, pi_initial_guess @ Sigma_list_trial[:,:,m] @ pi_initial_guess)\n",
        "    t_initial_guess = max(1e-6, t_initial_guess)\n",
        "    x_initial = np.concatenate([pi_initial_guess, [t_initial_guess]])\n",
        "    func = lambda x: x[-1]; cons = []\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, Sm=Sigma_list_trial[:,:,m]: x[-1] - x[:-1] @ Sm @ x[:-1]})\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, rm=R_trial[:,m]: x[:-1] @ rm - mu_tilde_val})\n",
        "    bounds = [(-np.inf, np.inf)] * k_assets + [(1e-8, np.inf)]\n",
        "    opt_res_Y0 = minimize(func, x_initial, method='SLSQP', bounds=bounds, constraints=cons, options={'ftol': 1e-8, 'disp': False, 'maxiter': 1000})\n",
        "    pi_Y = None; Y0_val = np.nan\n",
        "    if opt_res_Y0.success:\n",
        "        pi_sol, t_sol = opt_res_Y0.x[:-1], opt_res_Y0.x[-1]; feasible = True\n",
        "        min_ret_check = np.min(R_trial.T @ pi_sol)\n",
        "        max_quad_check = np.max([pi_sol @ Sigma_list_trial[:,:,m] @ pi_sol for m in range(m_models)])\n",
        "        if min_ret_check < mu_tilde_val - SOLVER_FEAS_TOL: feasible = False\n",
        "        if abs(t_sol - max_quad_check) > SOLVER_FEAS_TOL * (1 + abs(t_sol)) + 1e-7 : feasible = False\n",
        "        if feasible: pi_Y = pi_sol; Y0_val = t_sol\n",
        "    return pi_Y, Y0_val\n",
        "\n",
        "def calculate_X_pi_Y(pi_Y, R_trial, Sigma_list_trial, V_list_trial, k_assets, m_models):\n",
        "    if pi_Y is None: return np.nan\n",
        "    v_m_vec = np.array([pi_Y @ V_list_trial[:,:,m] @ pi_Y for m in range(m_models)])\n",
        "    a_m_vec = R_trial.T @ pi_Y\n",
        "    Q_mat = np.outer(a_m_vec, a_m_vec)\n",
        "    c_vec = v_m_vec + a_m_vec**2\n",
        "    obj_func = lambda w: w @ Q_mat @ w - c_vec @ w\n",
        "    jac_func = lambda w: 2 * Q_mat @ w - c_vec\n",
        "    bounds_w = Bounds(np.zeros(m_models), np.full(m_models, np.inf))\n",
        "    constraints_w = LinearConstraint(np.ones((1, m_models)), [1.0], [1.0])\n",
        "    w_initial = np.ones(m_models) / m_models\n",
        "    qp_res = minimize(obj_func, w_initial, method='SLSQP', jac=jac_func,\n",
        "                      bounds=bounds_w, constraints=constraints_w,\n",
        "                      options={'ftol': 1e-9, 'disp': False})\n",
        "    if qp_res.success:\n",
        "        w_opt_for_X = qp_res.x; w_opt_for_X = np.maximum(0, w_opt_for_X); w_opt_for_X /= np.sum(w_opt_for_X)\n",
        "        var_a_m = w_opt_for_X @ (a_m_vec**2) - (w_opt_for_X @ a_m_vec)**2\n",
        "        X_piY_val = w_opt_for_X @ v_m_vec + var_a_m # V_m is constant Vbar here\n",
        "        return max(0, X_piY_val)\n",
        "    else: return np.nan\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 3. INNER QP SOLVER (Replaces inner_halfpair)\n",
        "# ---------------------------------------------------------------------\n",
        "def solve_inner_qp(w_ij, R_alpha, Vbar_fixed, mu_tilde_val, k_assets, m_models):\n",
        "    \"\"\"Solves min_{pi in A(alpha)} pi^T V^w_ij pi\"\"\"\n",
        "    i, j = np.where(w_ij > 1e-6)[0] # Get indices i, j from w_ij\n",
        "    r_i, r_j = R_alpha[:, i], R_alpha[:, j]\n",
        "\n",
        "    # Calculate V^w_ij = Vbar + Cov_w_ij[r^m]\n",
        "    # Cov_w_ij[r^m] = 0.5*r_i*r_i^T + 0.5*r_j*r_j^T - (0.5*r_i+0.5*r_j)(0.5*r_i+0.5*r_j)^T\n",
        "    r_bar_ij = 0.5 * (r_i + r_j)\n",
        "    cov_r_ij = 0.5 * (np.outer(r_i, r_i) + np.outer(r_j, r_j)) - np.outer(r_bar_ij, r_bar_ij)\n",
        "    Vw_ij = Vbar_fixed + cov_r_ij\n",
        "\n",
        "    # Ensure Vw_ij is SPD for the QP solver\n",
        "    try:\n",
        "        min_eig_Vw_ij = np.min(np.linalg.eigvalsh(Vw_ij))\n",
        "        if min_eig_Vw_ij <= 1e-10: Vw_ij += np.eye(k_assets) * (abs(min_eig_Vw_ij) + 1e-8)\n",
        "    except np.linalg.LinAlgError: return np.nan, None # Cannot solve if Vw is problematic\n",
        "\n",
        "    # Objective: minimize 0.5 * pi^T (2 * Vw_ij) pi\n",
        "    P_qp = 2 * Vw_ij # Factor of 2 needed for standard QP form with 1/2\n",
        "    q_qp = np.zeros(k_assets) # No linear term in objective\n",
        "\n",
        "    # Constraints: A_ub @ pi <= b_ub  =>  -R_alpha^T @ pi <= -mu_tilde_val\n",
        "    A_ub = -R_alpha.T\n",
        "    b_ub = -np.full(m_models, mu_tilde_val)\n",
        "\n",
        "    # Initial guess (e.g., from previous Y0 calculation or simple)\n",
        "    pi_initial_guess = np.linalg.lstsq(R_alpha.T, np.full(m_models, mu_tilde_val), rcond=None)[0]\n",
        "    # Ensure initial guess is somewhat feasible for constraints\n",
        "    min_ret_init = np.min(R_alpha.T @ pi_initial_guess)\n",
        "    if min_ret_init < mu_tilde_val - INNER_OPT_TOL_FEAS:\n",
        "         # If lstsq doesn't work, try scaling equi-weight\n",
        "         pi_eq = np.ones(k_assets) / k_assets\n",
        "         min_ret_eq = np.min(R_alpha.T @ pi_eq)\n",
        "         if min_ret_eq > 1e-9 : # Avoid division by zero/small\n",
        "             pi_initial_guess = pi_eq * (mu_tilde_val / min_ret_eq) * 1.01 # Scale up\n",
        "         else: # Fallback if equi-weight also fails\n",
        "             pi_initial_guess = pi_eq # Use unscaled\n",
        "\n",
        "    # Define objective and constraints for scipy.optimize.minimize\n",
        "    obj_func_qp = lambda pi: 0.5 * pi @ P_qp @ pi\n",
        "    jac_func_qp = lambda pi: P_qp @ pi # Gradient = P_qp * pi\n",
        "\n",
        "    # Constraints Ax >= b => -Ax <= -b\n",
        "    constraints_qp = [{'type': 'ineq', 'fun': lambda pi, m=m: pi @ R_alpha[:,m] - mu_tilde_val} for m in range(m_models)]\n",
        "\n",
        "    # Solve the QP\n",
        "    qp_result = minimize(obj_func_qp, pi_initial_guess, method='SLSQP',\n",
        "                         jac=jac_func_qp, constraints=constraints_qp,\n",
        "                         options={'ftol': 1e-9, 'disp': False})\n",
        "\n",
        "    if qp_result.success:\n",
        "        pi_sol = qp_result.x\n",
        "        # Verify feasibility of solution strictly\n",
        "        if np.min(R_alpha.T @ pi_sol) >= mu_tilde_val - SOLVER_FEAS_TOL:\n",
        "            # Calculate the true objective value H_ij = pi_sol^T Vw_ij pi_sol\n",
        "            H_ij_val = pi_sol @ Vw_ij @ pi_sol\n",
        "            return H_ij_val, pi_sol\n",
        "        else:\n",
        "            # print(f\"Warning: QP solution for pair ({i},{j}) infeasible. Min ret: {np.min(R_alpha.T @ pi_sol)}\")\n",
        "            return np.nan, None\n",
        "    else:\n",
        "        # print(f\"Warning: Inner QP solver failed for pair ({i},{j}). Status: {qp_result.status}, Msg: {qp_result.message}\")\n",
        "        return np.nan, None\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 4. CALCULATE BOUNDS and SR_rob (for exact ½–½ case)\n",
        "# ---------------------------------------------------------------------\n",
        "def calculate_bounds_and_sr_exact_halfpair(pi_star, w_star, H_star_val, R_alpha, Sigma_alpha, Vbar_fixed):\n",
        "    # This function now assumes H_star_val is the true max_ij H_ij^* = pi_star^T V^w_star pi_star\n",
        "    SR_rob_val, B_U1_val, B_U2_val = np.nan, np.nan, np.nan\n",
        "    if pi_star is None or w_star is None or np.isnan(H_star_val): return SR_rob_val, B_U1_val, B_U2_val\n",
        "\n",
        "    # SR_rob: Use the H_star_val directly as denominator^2\n",
        "    r_bar_ws = R_alpha @ w_star; numerator_sr = pi_star @ r_bar_ws\n",
        "    denominator_sr_sq = H_star_val # H_star_val IS pi* Vw* pi*\n",
        "    if denominator_sr_sq > 1e-12: SR_rob_val = numerator_sr / np.sqrt(denominator_sr_sq)\n",
        "    elif abs(numerator_sr) < GENTOL: SR_rob_val = 0.0\n",
        "\n",
        "    # B_U1 = sqrt(S(w*))\n",
        "    # Calculate Vw* again (or pass it?)\n",
        "    Sigma_w_star_bar = np.sum(np.fromiter((w_star[m] * Sigma_alpha[:, :, m] for m in range(M)), dtype=object))\n",
        "    Vw_star = Sigma_w_star_bar - np.outer(r_bar_ws, r_bar_ws)\n",
        "    try:\n",
        "        Vw_star_inv = np.linalg.inv(Vw_star + np.eye(K)*1e-10); s_w_star_num = r_bar_ws @ Vw_star_inv @ r_bar_ws\n",
        "        if s_w_star_num < -GENTOL: s_w_star_num = 0; B_U1_val = np.sqrt(s_w_star_num)\n",
        "    except np.linalg.LinAlgError: B_U1_val = np.nan\n",
        "\n",
        "    # B_U2 = sqrt(rho_max / (1-rho_max))\n",
        "    rho_m_vals = np.zeros(M); all_rho_m_ok = True\n",
        "    for m in range(M):\n",
        "        try: Sigma_m_inv = np.linalg.inv(Sigma_alpha[:,:,m] + np.eye(K)*1e-10); rho_m_vals[m] = R_alpha[:,m] @ Sigma_m_inv @ R_alpha[:,m]\n",
        "        except np.linalg.LinAlgError: all_rho_m_ok = False; break\n",
        "    if all_rho_m_ok:\n",
        "        rho_max_val = np.max(rho_m_vals); rho_max_val = min(rho_max_val, 1.0 - 1e-12)\n",
        "        if rho_max_val < 0: B_U2_val = np.nan\n",
        "        else: B_U2_val = np.sqrt(rho_max_val / (1.0 - rho_max_val))\n",
        "    else: B_U2_val = np.nan\n",
        "    return SR_rob_val, B_U1_val, B_U2_val\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 5. FINITE DIFFERENCE HELPER\n",
        "# ---------------------------------------------------------------------\n",
        "def finite_diff_vec(v_p, v_m, h, length):\n",
        "    if v_p is None or v_m is None or h is None or np.isnan(h) or abs(h) < FINITE_DIFF_EPS: return np.full(length, np.nan)\n",
        "    actual_h = h if abs(h) > FINITE_DIFF_EPS else np.sign(h)*FINITE_DIFF_EPS if h!=0 else FINITE_DIFF_EPS\n",
        "    return (v_p - v_m) / (2 * actual_h)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 6. α-SWEEP MAIN FUNCTION (Exact QP for ½–½ case)\n",
        "# ---------------------------------------------------------------------\n",
        "def run_alpha_sweep_halfpair_exact_qp(csv_path=\"halfpair_exact_qp_bounds_dpi.csv\"):\n",
        "    log = logging.getLogger(\"sweep_halfpair_exact\")\n",
        "    log.propagate = False\n",
        "    log.setLevel(logging.INFO)\n",
        "    if not log.handlers: log.addHandler(logging.StreamHandler(sys.stdout))\n",
        "    log.info(\"========== ½–½ Exact QP α-Sweep Full Bounds with dpi* START ==========\")\n",
        "\n",
        "    col_w   = [f\"w*_m{m}\"   for m in range(M)]\n",
        "    col_pi  = [f\"pi*_k{k}\"  for k in range(K)]\n",
        "    col_ret = [f\"cstr_ret_m{m}\" for m in range(M)]\n",
        "    col_lam = [f\"lam_m{m}\"  for m in range(M)] # Note: QP doesn't directly give lambda_m for robust problem\n",
        "    col_dpi = [f\"dpi*_k{k}\" for k in range(K)]\n",
        "    columns = ([\"alpha\", \"H_star\", \"supp_w\", \"lambda_min_Vbar\", \"iterations\", # iterations not applicable\n",
        "                \"SR_rob\", \"SR_Bound_Sw\", \"SR_Bound_rho_max\",\n",
        "                \"SR_Bound_Y0\", \"SR_Bound_XpiY\",\n",
        "                \"Y0_val\", \"XpiY_val\"]\n",
        "               + col_w + col_pi + col_ret + col_lam + col_dpi)\n",
        "\n",
        "    rows, cache = [], {}      # cache[alpha] = dict(pi_star, w_star, H_star)\n",
        "    rng_y0 = np.random.default_rng(12345)\n",
        "    t0 = datetime.now()\n",
        "    y0_fail_count = 0; xpiy_fail_count = 0; inner_qp_fail_count = 0\n",
        "\n",
        "    # --- Define get helper for caching exact halfpair results ---\n",
        "    def get_exact_halfpair(alpha_val):\n",
        "        cache_key = alpha_val\n",
        "        if cache_key not in cache:\n",
        "            try:\n",
        "                R_a, Sigma_a, V_a = get_params_r_only(alpha_val)\n",
        "                best_H_star_a = -math.inf; best_result_a = None; num_qp_fails = 0\n",
        "\n",
        "                for i, j in itertools.combinations(range(M), 2):\n",
        "                    w_ij = np.zeros(M); w_ij[[i,j]] = 0.5\n",
        "                    H_ij_val, pi_ij = solve_inner_qp(w_ij, R_a, Vbar, mu_tilde, K, M)\n",
        "\n",
        "                    if pi_ij is None or np.isnan(H_ij_val):\n",
        "                        num_qp_fails += 1; continue # Count failure but continue\n",
        "\n",
        "                    if H_ij_val > best_H_star_a:\n",
        "                        best_H_star_a = H_ij_val\n",
        "                        # Store necessary info associated with the best pair found so far\n",
        "                        best_result_a = {\"H_star\": H_ij_val, \"pi_star\": pi_ij, \"w_star\": w_ij,\n",
        "                                         \"R\": R_a, \"Sigma\": Sigma_a, \"V\": V_a} # Keep V_a (copies of Vbar)\n",
        "\n",
        "                if best_result_a is None: # If all pairs failed\n",
        "                    raise ValueError(f\"All inner QPs failed for alpha={alpha_val}\")\n",
        "\n",
        "                cache[cache_key] = best_result_a\n",
        "                # Log if some QPs failed but an overall best was found\n",
        "                # if num_qp_fails > 0: log.debug(f\"Alpha {alpha_val:.3f}: {num_qp_fails} inner QPs failed.\")\n",
        "\n",
        "            except Exception as e:\n",
        "                # log.warning(f\"Get_exact_halfpair failed for alpha={alpha_val}. Error: {e}\")\n",
        "                cache[cache_key] = None\n",
        "        return cache[cache_key]\n",
        "    # --- End of get helper ---\n",
        "\n",
        "    for idx, alpha in enumerate(ALPHA_GRID):\n",
        "        if (idx * 100 // N_ALPHA) > ((idx - 1) * 100 // N_ALPHA):\n",
        "             log.info(f\"Progress: {idx * 100 / N_ALPHA:.0f}% (α = {alpha:.5f})\")\n",
        "\n",
        "        res_c = get_exact_halfpair(alpha)\n",
        "\n",
        "        if res_c is None:\n",
        "            inner_qp_fail_count += 1 # Increment failure count based on get helper result\n",
        "            continue\n",
        "\n",
        "        H_star  = res_c[\"H_star\"]; pi_star = res_c[\"pi_star\"]; w_star = res_c[\"w_star\"]\n",
        "        R_th = res_c[\"R\"]; Sigma_th = res_c[\"Sigma\"]; V_th = res_c[\"V\"] # V_th contains copies of Vbar\n",
        "\n",
        "        SR_rob, B_U1, B_U2 = calculate_bounds_and_sr_exact_halfpair(pi_star, w_star, H_star, R_th, Sigma_th, Vbar)\n",
        "        pi_Y, Y0_val = calculate_Y0(R_th, Sigma_th, mu_tilde, K, M, rng_y0)\n",
        "        if pi_Y is None or np.isnan(Y0_val): y0_fail_count += 1\n",
        "        XpiY_val = calculate_X_pi_Y(pi_Y, R_th, Sigma_th, V_th, K, M)\n",
        "        if pi_Y is not None and np.isnan(XpiY_val): xpiy_fail_count += 1\n",
        "        B_L1 = mu_tilde / np.sqrt(Y0_val) if Y0_val is not None and not np.isnan(Y0_val) and Y0_val > 1e-12 else np.nan\n",
        "        B_L2 = mu_tilde / np.sqrt(XpiY_val) if XpiY_val is not None and not np.isnan(XpiY_val) and XpiY_val > 1e-12 else np.nan\n",
        "\n",
        "        # --- Calculate dpi* (Finite Difference) using get ---\n",
        "        dpi_star = np.full(K, np.nan)\n",
        "        prev_alpha = ALPHA_GRID[idx - 1] if idx > 0 else None\n",
        "        next_alpha = ALPHA_GRID[idx + 1] if idx < N_ALPHA - 1 else None\n",
        "        h = np.nan; pi_p, pi_m = None, None\n",
        "        if prev_alpha is not None and next_alpha is not None:\n",
        "            h = min(alpha - prev_alpha, next_alpha - alpha)\n",
        "            if h < FINITE_DIFF_EPS: h = FINITE_DIFF_EPS\n",
        "            res_p = get_exact_halfpair(alpha + h)\n",
        "            res_m = get_exact_halfpair(alpha - h)\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / (2*h)\n",
        "        elif prev_alpha is None and next_alpha is not None:\n",
        "            h = next_alpha - alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_p = get_exact_halfpair(next_alpha); pi_m = pi_star\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "        elif next_alpha is None and prev_alpha is not None:\n",
        "            h = alpha - prev_alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_m = get_exact_halfpair(prev_alpha); pi_p = pi_star\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "\n",
        "        # --- Format other outputs ---\n",
        "        cstr_ret = R_th.T @ pi_star if pi_star is not None else np.full(M, np.nan)\n",
        "        # Lagrange multipliers for the robust problem are not directly computed here\n",
        "        lam_vec = np.full(M, np.nan)\n",
        "\n",
        "        # --- Append row ---\n",
        "        row_data = {\"alpha\": alpha, \"H_star\": H_star, \"supp_w\": 2, \"lambda_min_Vbar\": lambda_min_Vbar,\n",
        "                    \"iterations\": np.nan, \"SR_rob\": SR_rob, \"SR_Bound_Sw\": B_U1, \"SR_Bound_rho_max\": B_U2,\n",
        "                    \"SR_Bound_Y0\": B_L1, \"SR_Bound_XpiY\": B_L2, \"Y0_val\": Y0_val, \"XpiY_val\": XpiY_val}\n",
        "        row_data.update({f\"w*_m{m}\": w_star[m] for m in range(M)})\n",
        "        row_data.update({f\"pi*_k{k}\": pi_star[k] for k in range(K)})\n",
        "        row_data.update({f\"cstr_ret_m{m}\": cstr_ret[m] for m in range(M)})\n",
        "        row_data.update({f\"lam_m{m}\": lam_vec[m] for m in range(M)}) # Placeholder NaN\n",
        "        row_data.update({f\"dpi*_k{k}\": dpi_star[k] for k in range(K)})\n",
        "        rows.append(row_data)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "    df.to_csv(csv_path, index=False, float_format=\"%.10g\")\n",
        "    log.info(f\"CSV written to {csv_path}  (elapsed {(datetime.now() - t0).total_seconds():.1f}s)\")\n",
        "    log.info(f\"Total Inner QP Fails (at least one pair failed): {inner_qp_fail_count}, Y0 Fails: {y0_fail_count}, XpiY Fails: {xpiy_fail_count}\")\n",
        "    return df\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 7. MAIN EXECUTION\n",
        "# ---------------------------------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    run_alpha_sweep_halfpair_exact_qp()"
      ],
      "metadata": {
        "id": "RhMiunhIB1Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$sigma^m$のみが異なる場合"
      ],
      "metadata": {
        "id": "xL88xfYYQDSd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "sigma_only_sweep_full_bounds_dpi.py\n",
        "- Robust MVP (r, C fixed, sigma varies) α-sweep.\n",
        "- Calculates bounds from Thm 2 (S(w*)), Thm 6 (Y0), Thm 8 (X_piY).\n",
        "- Includes dpi* calculation.\n",
        "Based on the provided sigma_only script.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.linalg as la\n",
        "from datetime import datetime\n",
        "from scipy.optimize import minimize, Bounds, LinearConstraint # For Y0, X_piY\n",
        "import logging, sys\n",
        "\n",
        "# ... (Global constants and other functions remain the same) ...\n",
        "K, M = 4, 4\n",
        "mu_tilde = 0.03\n",
        "\n",
        "ALPHA_GRID   = np.linspace(ALPHA_MIN, ALPHA_MAX, N_ALPHA)\n",
        "MAX_OPT_ITERS = 1000\n",
        "tol_grad = 1e-8\n",
        "step_size_norm_threshold = 1e-10\n",
        "INNER_OPT_TOL_FEAS = 1e-9\n",
        "SOLVER_FEAS_TOL    = 1e-7\n",
        "GENTOL             = 1e-9\n",
        "FINITE_DIFF_EPS    = 1e-12\n",
        "r_bar = np.array([0.02, 0.03, 0.04, 0.05])\n",
        "sigma_base = np.array([0.20, 0.25, 0.30, 0.35])\n",
        "Delta_A =np.array([[+1, 1, -1, -1],[+1, 1, -1, -1],\n",
        "                   [+2, -1, +2, -2],[+2, -2, +2, -2]], dtype=float)\n",
        "Delta_sigma_m = Delta_A / 100\n",
        "def block_corr(rho_in, rho_out):\n",
        "    C = np.full((K, K), rho_out); np.fill_diagonal(C, 1.0)\n",
        "    for i, j in ((0, 1), (2, 3)): C[i, j] = C[j, i] = rho_in\n",
        "    return C\n",
        "C_base = block_corr(0.75, 0.50)\n",
        "def proj_simplex(v):\n",
        "    v = np.asarray(v, float)\n",
        "    if (v >= 0).all() and np.isclose(v.sum(), 1.0, atol=1e-10): return v\n",
        "    u = np.sort(v)[::-1]; cssv = np.cumsum(u) - 1\n",
        "    try:\n",
        "        idx_rho = np.where(u * (np.arange(len(u)) + 1) > cssv)[0]\n",
        "        rho = idx_rho[-1] if len(idx_rho) > 0 else len(u) - 1\n",
        "        theta = cssv[rho] / (rho + 1); return np.maximum(v - theta, 0.0)\n",
        "    except IndexError: return np.ones_like(v) / len(v)\n",
        "def build_params_sigma_only(alpha):\n",
        "    R_th = np.tile(r_bar[:, np.newaxis], (1, M))\n",
        "    Sigma_th = np.zeros((K, K, M)); V_th = np.zeros((K, K, M))\n",
        "    lambda_min_V_log = []; reg_V = 1e-8; reg_S = 1e-8\n",
        "    for m in range(M):\n",
        "        σ = sigma_base + alpha * Delta_sigma_m[:, m]\n",
        "        V_m = np.diag(σ) @ C_base @ np.diag(σ)\n",
        "        min_eig_Vm = np.min(np.linalg.eigvalsh(V_m))\n",
        "        if min_eig_Vm <= reg_V: V_m += np.eye(K) * (abs(min_eig_Vm) + reg_V)\n",
        "        V_th[:, :, m] = V_m\n",
        "        lambda_min_V_log.append(np.min(np.linalg.eigvalsh(V_m)))\n",
        "        Sigma_th[:, :, m] = V_m + np.outer(r_bar, r_bar)\n",
        "        min_eig_Sm = np.min(np.linalg.eigvalsh(Sigma_th[:, :, m]))\n",
        "        if min_eig_Sm <= reg_S: Sigma_th[:, :, m] += np.eye(K) * (abs(min_eig_Sm) + reg_S)\n",
        "    lambda_min_for_csv = float(min(lambda_min_V_log)) if lambda_min_V_log else np.nan\n",
        "    return R_th, Sigma_th, V_th, lambda_min_for_csv\n",
        "def calculate_Y0(R_trial, Sigma_list_trial, mu_tilde_val, k_assets, m_models, rng_y0_pert):\n",
        "    pi_avg_r = np.mean(R_trial, axis=1); k_assets=R_trial.shape[0]; m_models=R_trial.shape[1]\n",
        "    if np.linalg.norm(pi_avg_r) > 1e-6: pi_initial_guess = pi_avg_r / np.linalg.norm(pi_avg_r)\n",
        "    else: pi_initial_guess = np.ones(k_assets) / np.sqrt(k_assets)\n",
        "    max_tries_feas = 10; found_feasible_pi = False; SOLVER_FEAS_TOL=1e-7\n",
        "    constraint_func = lambda pi: pi @ R_trial[:, 0] - mu_tilde_val\n",
        "    for i_try in range(max_tries_feas):\n",
        "        if constraint_func(pi_initial_guess) >= -SOLVER_FEAS_TOL : found_feasible_pi = True; break\n",
        "        else: current_ret = pi_initial_guess @ R_trial[:, 0]\n",
        "        if current_ret > 1e-9: pi_initial_guess *= (mu_tilde_val / current_ret) * (1.01 + 0.1*i_try)\n",
        "        else: pi_initial_guess += rng_y0_pert.normal(0, 0.1, size=k_assets); norm_pi = np.linalg.norm(pi_initial_guess); pi_initial_guess /= norm_pi if norm_pi > 1e-6 else 1\n",
        "    if not found_feasible_pi: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "    t_initial_guess = 0.0\n",
        "    for m in range(m_models): t_initial_guess = max(t_initial_guess, pi_initial_guess @ Sigma_list_trial[:,:,m] @ pi_initial_guess)\n",
        "    t_initial_guess = max(1e-6, t_initial_guess)\n",
        "    x_initial = np.concatenate([pi_initial_guess, [t_initial_guess]])\n",
        "    func = lambda x: x[-1]; cons = []\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, Sm=Sigma_list_trial[:,:,m]: x[-1] - x[:-1] @ Sm @ x[:-1]})\n",
        "    cons.append({'type': 'ineq', 'fun': lambda x, rm=R_trial[:,0]: x[:-1] @ rm - mu_tilde_val})\n",
        "    bounds = [(-np.inf, np.inf)] * k_assets + [(1e-8, np.inf)]\n",
        "    opt_res_Y0 = minimize(func, x_initial, method='SLSQP', bounds=bounds, constraints=cons, options={'ftol': 1e-8, 'disp': False, 'maxiter': 1000})\n",
        "    pi_Y = None; Y0_val = np.nan\n",
        "    if opt_res_Y0.success:\n",
        "        pi_sol, t_sol = opt_res_Y0.x[:-1], opt_res_Y0.x[-1]; feasible = True\n",
        "        min_ret_check = pi_sol @ R_trial[:,0]\n",
        "        max_quad_check = np.max([pi_sol @ Sigma_list_trial[:,:,m] @ pi_sol for m in range(m_models)])\n",
        "        if min_ret_check < mu_tilde_val - SOLVER_FEAS_TOL: feasible = False\n",
        "        if abs(t_sol - max_quad_check) > SOLVER_FEAS_TOL * (1 + abs(t_sol)) + 1e-7 : feasible = False\n",
        "        if feasible: pi_Y = pi_sol; Y0_val = t_sol\n",
        "    return pi_Y, Y0_val\n",
        "def calculate_X_pi_Y(pi_Y, R_trial, Sigma_list_trial, V_list_trial, k_assets, m_models):\n",
        "    if pi_Y is None: return np.nan\n",
        "    v_m_vec = np.array([pi_Y @ V_list_trial[:,:,m] @ pi_Y for m in range(m_models)])\n",
        "    a_m_vec = R_trial[:,0].T @ pi_Y; a_m_vec_rep = np.full(m_models, a_m_vec)\n",
        "    Q_mat = np.outer(a_m_vec_rep, a_m_vec_rep); c_vec = v_m_vec + a_m_vec_rep**2\n",
        "    obj_func = lambda w: w @ Q_mat @ w - c_vec @ w; jac_func = lambda w: 2 * Q_mat @ w - c_vec\n",
        "    bounds_w = Bounds(np.zeros(m_models), np.full(m_models, np.inf))\n",
        "    constraints_w = LinearConstraint(np.ones((1, m_models)), [1.0], [1.0])\n",
        "    w_initial = np.ones(m_models) / m_models\n",
        "    qp_res = minimize(obj_func, w_initial, method='SLSQP', jac=jac_func, bounds=bounds_w, constraints=constraints_w, options={'ftol': 1e-9, 'disp': False})\n",
        "    if qp_res.success:\n",
        "        w_opt_for_X = qp_res.x; w_opt_for_X = np.maximum(0, w_opt_for_X); w_opt_for_X /= np.sum(w_opt_for_X)\n",
        "        var_a_m = 0.0; X_piY_val = w_opt_for_X @ v_m_vec + var_a_m\n",
        "        return max(0, X_piY_val)\n",
        "    else: return np.nan\n",
        "def phi_and_grad(w, R_common, Sigma_alpha): # Added R_common argument\n",
        "    V_list = [Sigma_alpha[:,:,m] - np.outer(R_common[:,0], R_common[:,0]) for m in range(M)]\n",
        "    Vw = np.sum(np.fromiter((w[m] * V_list[m] for m in range(M)), dtype=object))\n",
        "    try:\n",
        "        Vw_reg = Vw + np.eye(K) * 1e-9\n",
        "        y = la.solve(Vw_reg, R_common[:,0], assume_a='pos')\n",
        "        phi = R_common[:,0] @ y\n",
        "        grad = -np.array([y @ V_list[m] @ y for m in range(M)])\n",
        "    except (np.linalg.LinAlgError, ValueError):\n",
        "        try: Vw_pinv = np.linalg.pinv(Vw_reg); y = Vw_pinv @ R_common[:,0]; phi = R_common[:,0] @ y; grad = -np.array([y @ V_list[m] @ y for m in range(M)])\n",
        "        except np.linalg.LinAlgError: return np.inf, np.full(M, np.nan)\n",
        "    return phi, grad\n",
        "def minimise_phi(R_common, Sigma_alpha, w0=None):\n",
        "    w = proj_simplex(w0 if w0 is not None else np.ones(M) / M)\n",
        "    phi, g = phi_and_grad(w, R_common, Sigma_alpha)\n",
        "    if np.isnan(g).any(): return np.inf, w, 0\n",
        "    lr = 0.1\n",
        "    for it in range(1, MAX_OPT_ITERS + 1):\n",
        "        proj_grad_norm = np.linalg.norm(w - proj_simplex(w - g))\n",
        "        if proj_grad_norm < tol_grad: break\n",
        "        w_prev = w.copy(); phi_prev = phi; alpha_ls = 0.3; beta_ls = 0.7; lr_curr = lr * 2\n",
        "        accepted_step = False\n",
        "        for _ls_iter in range(20):\n",
        "             lr_curr *= beta_ls; w_new = proj_simplex(w - lr_curr * g)\n",
        "             phi_new, g_new = phi_and_grad(w_new, R_common, Sigma_alpha)\n",
        "             if np.isnan(g_new).any(): continue\n",
        "             if phi_new <= phi_prev - 1e-9 * lr_curr * (g @ g):\n",
        "                 w, phi, g = w_new, phi_new, g_new; lr = lr_curr; accepted_step = True; break\n",
        "        if not accepted_step: break\n",
        "    return phi, w, it\n",
        "def calculate_bounds_and_sr_sigma_only(pi_star, w_star, H_star_val, R_common, Sigma_alpha, V_alpha):\n",
        "    SR_rob_val, B_U1_val, B_U2_val = np.nan, np.nan, np.nan\n",
        "    if pi_star is None or w_star is None or np.isnan(H_star_val): return SR_rob_val, B_U1_val, B_U2_val\n",
        "    r_bar_ws = R_common[:,0]; numerator_sr = pi_star @ r_bar_ws\n",
        "    denominator_sr_sq = H_star_val\n",
        "    if denominator_sr_sq > 1e-12: SR_rob_val = numerator_sr / np.sqrt(denominator_sr_sq)\n",
        "    elif abs(numerator_sr) < GENTOL: SR_rob_val = 0.0\n",
        "    Vw_star = np.sum(np.fromiter((w_star[m] * V_alpha[:,:,m] for m in range(M)), dtype=object))\n",
        "    try: Vw_star_inv = np.linalg.inv(Vw_star + np.eye(K)*1e-10); s_w_star_num = r_bar_ws @ Vw_star_inv @ r_bar_ws\n",
        "    except np.linalg.LinAlgError: B_U1_val = np.nan; s_w_star_num = -1\n",
        "    else:\n",
        "        if s_w_star_num < -GENTOL: s_w_star_num = 0\n",
        "        B_U1_val = np.sqrt(s_w_star_num)\n",
        "    rho_m_vals = np.zeros(M); all_rho_m_ok = True\n",
        "    for m in range(M):\n",
        "        try: Sigma_m_inv = np.linalg.inv(Sigma_alpha[:,:,m] + np.eye(K)*1e-10); rho_m_vals[m] = r_bar_ws @ Sigma_m_inv @ r_bar_ws\n",
        "        except np.linalg.LinAlgError: all_rho_m_ok = False; break\n",
        "    if all_rho_m_ok:\n",
        "        rho_max_val = np.max(rho_m_vals); rho_max_val = min(rho_max_val, 1.0 - 1e-12)\n",
        "        if rho_max_val < 0: B_U2_val = np.nan\n",
        "        else: B_U2_val = np.sqrt(rho_max_val / (1.0 - rho_max_val))\n",
        "    else: B_U2_val = np.nan\n",
        "    return SR_rob_val, B_U1_val, B_U2_val\n",
        "def finite_diff_vec(v_p, v_m, h, length):\n",
        "    if v_p is None or v_m is None or h is None or np.isnan(h) or abs(h) < FINITE_DIFF_EPS: return np.full(length, np.nan)\n",
        "    actual_h = h if abs(h) > FINITE_DIFF_EPS else np.sign(h)*FINITE_DIFF_EPS if h!=0 else FINITE_DIFF_EPS\n",
        "    return (v_p - v_m) / (2 * actual_h)\n",
        "\n",
        "# --------------------------- α-sweep (sigma only case) ---------------------\n",
        "def run_sweep_sigma_only_full_bounds(out_csv=\"sigma_only_sweep_full_bounds_dpi.csv\"):\n",
        "    log = logging.getLogger(\"sweep_sigma\")\n",
        "    log.propagate = False\n",
        "    log.setLevel(logging.INFO)\n",
        "    if not log.handlers: log.addHandler(logging.StreamHandler(sys.stdout))\n",
        "    log.info(\"========== Sigma Only α-Sweep Full Bounds with dpi* START ==========\")\n",
        "\n",
        "    # *** ADD COLUMN DEFINITIONS HERE ***\n",
        "    col_w   = [f\"w*_m{m}\" for m in range(M)]\n",
        "    col_pi  = [f\"pi*_k{k}\" for k in range(K)]\n",
        "    col_ret = [f\"cstr_ret_m{m}\" for m in range(M)]\n",
        "    col_lam = [f\"lam_m{m}\" for m in range(M)]\n",
        "    col_dpi = [f\"dpi*_k{k}\" for k in range(K)]\n",
        "    columns = ([\"alpha\", \"H_star\", \"supp_w\", \"lambda_min_Vm\", \"iterations\",\n",
        "                \"SR_rob\", \"SR_Bound_Sw\", \"SR_Bound_rho_max\",\n",
        "                \"SR_Bound_Y0\", \"SR_Bound_XpiY\",\n",
        "                \"Y0_val\", \"XpiY_val\"]\n",
        "               + col_w + col_pi + col_ret + col_lam + col_dpi)\n",
        "\n",
        "    rows, cache = [], {}\n",
        "    rng_y0 = np.random.default_rng(23456)\n",
        "    t0 = datetime.now()\n",
        "    y0_fail_count = 0; xpiy_fail_count = 0; phi_fail_count = 0\n",
        "\n",
        "    def get_sigma_only_pi(alpha_val):\n",
        "        cache_key = alpha_val\n",
        "        if cache_key not in cache:\n",
        "            try:\n",
        "                R_a, Sigma_a, V_a, lambda_min_a = build_params_sigma_only(alpha_val)\n",
        "                phi_star_a, w_star_a, iters_a = minimise_phi(R_a, Sigma_a)\n",
        "                if np.isinf(phi_star_a): raise ValueError(\"minimise_phi failed\")\n",
        "                Vw_star_a = np.sum(np.fromiter((w_star_a[m] * V_a[:,:,m] for m in range(M)), dtype=object))\n",
        "                Vw_star_a_inv = np.linalg.inv(Vw_star_a + np.eye(K)*1e-10)\n",
        "                r_Vinv_r_a = R_a[:,0] @ Vw_star_a_inv @ R_a[:,0]\n",
        "                if r_Vinv_r_a <= 1e-9: raise ValueError(\"r_Vinv_r near zero\")\n",
        "                pi_star_a = (mu_tilde * Vw_star_a_inv @ R_a[:,0]) / r_Vinv_r_a\n",
        "                cache[cache_key] = {\"pi_star\": pi_star_a}\n",
        "            except Exception as e: cache[cache_key] = None\n",
        "        return cache[cache_key]\n",
        "\n",
        "    for idx, alpha in enumerate(ALPHA_GRID):\n",
        "        if (idx * 100 // N_ALPHA) > ((idx - 1) * 100 // N_ALPHA):\n",
        "             log.info(f\"Progress: {idx * 100 / N_ALPHA:.0f}% (α = {alpha:.5f})\")\n",
        "        try:\n",
        "            R_th, Sigma_th, V_th, lambda_min_val = build_params_sigma_only(alpha)\n",
        "            phi_star, w_star, nit = minimise_phi(R_th, Sigma_th)\n",
        "            if np.isinf(phi_star): raise ValueError(\"minimise_phi failed\")\n",
        "            Vw_star = np.sum(np.fromiter((w_star[m] * V_th[:,:,m] for m in range(M)), dtype=object))\n",
        "            Vw_star_inv = np.linalg.inv(Vw_star + np.eye(K)*1e-10)\n",
        "            r_Vinv_r = R_th[:,0] @ Vw_star_inv @ R_th[:,0]\n",
        "            if r_Vinv_r <= 1e-9: raise ValueError(\"r_Vinv_r near zero in main loop\")\n",
        "            pi_star = (mu_tilde * Vw_star_inv @ R_th[:,0]) / r_Vinv_r\n",
        "            H_star = mu_tilde**2 / phi_star\n",
        "        except Exception as e:\n",
        "            log.warning(f\"Skipping alpha = {alpha:.5f} due to error in main calc: {e}\")\n",
        "            phi_fail_count += 1\n",
        "            continue\n",
        "        if alpha not in cache: cache[alpha] = {\"pi_star\": pi_star}\n",
        "        SR_rob, B_U1, B_U2 = calculate_bounds_and_sr_sigma_only(pi_star, w_star, H_star, R_th, Sigma_th, V_th)\n",
        "        pi_Y, Y0_val = calculate_Y0(R_th, Sigma_th, mu_tilde, K, M, rng_y0)\n",
        "        if pi_Y is None or np.isnan(Y0_val): y0_fail_count += 1\n",
        "        XpiY_val = calculate_X_pi_Y(pi_Y, R_th, Sigma_th, V_th, K, M)\n",
        "        if pi_Y is not None and np.isnan(XpiY_val): xpiy_fail_count += 1\n",
        "        B_L1 = mu_tilde / np.sqrt(Y0_val) if Y0_val is not None and not np.isnan(Y0_val) and Y0_val > 1e-12 else np.nan\n",
        "        B_L2 = mu_tilde / np.sqrt(XpiY_val) if XpiY_val is not None and not np.isnan(XpiY_val) and XpiY_val > 1e-12 else np.nan\n",
        "        dpi_star = np.full(K, np.nan); prev_alpha = ALPHA_GRID[idx - 1] if idx > 0 else None\n",
        "        next_alpha = ALPHA_GRID[idx + 1] if idx < N_ALPHA - 1 else None; h = np.nan; pi_p, pi_m = None, None\n",
        "        if prev_alpha is not None and next_alpha is not None:\n",
        "            h = min(alpha - prev_alpha, next_alpha - alpha); h = max(h, FINITE_DIFF_EPS)\n",
        "            res_p = get_sigma_only_pi(alpha + h); res_m = get_sigma_only_pi(alpha - h)\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / (2*h)\n",
        "        elif prev_alpha is None and next_alpha is not None:\n",
        "            h = next_alpha - alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_p = get_sigma_only_pi(next_alpha); pi_m = pi_star\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "        elif next_alpha is None and prev_alpha is not None:\n",
        "            h = alpha - prev_alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_m = get_sigma_only_pi(prev_alpha); pi_p = pi_star\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "        cstr_ret = np.full(M, mu_tilde); lam_vec = np.full(M, np.nan)\n",
        "        row_data = {\"alpha\": alpha, \"H_star\": H_star, \"supp_w\": int((w_star > 1e-6).sum()),\n",
        "                    \"lambda_min_Vm\": lambda_min_val, \"iterations\": nit, \"SR_rob\": SR_rob,\n",
        "                    \"SR_Bound_Sw\": B_U1, \"SR_Bound_rho_max\": B_U2, \"SR_Bound_Y0\": B_L1, \"SR_Bound_XpiY\": B_L2,\n",
        "                    \"Y0_val\": Y0_val, \"XpiY_val\": XpiY_val}\n",
        "        row_data.update({f\"w*_m{m}\": w_star[m] for m in range(M)})\n",
        "        row_data.update({f\"pi*_k{k}\": pi_star[k] for k in range(K)})\n",
        "        row_data.update({f\"cstr_ret_m{m}\": cstr_ret[m] for m in range(M)})\n",
        "        row_data.update({f\"lam_m{m}\": lam_vec[m] for m in range(M)})\n",
        "        row_data.update({f\"dpi*_k{k}\": dpi_star[k] for k in range(K)})\n",
        "        rows.append(row_data)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "    df.to_csv(out_csv, index=False, float_format=\"%.10g\")\n",
        "    log.info(f\"CSV written to {out_csv}  (elapsed {(datetime.now() - t0).total_seconds():.1f}s)\")\n",
        "    log.info(f\"Total Phi Minimization Fails: {phi_fail_count}, Y0 Fails: {y0_fail_count}, XpiY Fails: {xpiy_fail_count}\")\n",
        "    return df\n",
        "\n",
        "# --------------------------- MAIN --------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Define ALPHA_MIN, ALPHA_MAX, N_ALPHA before calling\n",
        "    # Example:\n",
        "    ALPHA_MIN = 0.01\n",
        "    ALPHA_MAX = 1.0\n",
        "    N_ALPHA = 101 # Reduce N_ALPHA for testing\n",
        "    ALPHA_GRID = np.linspace(ALPHA_MIN, ALPHA_MAX, N_ALPHA)\n",
        "\n",
        "    df_preview = run_sweep_sigma_only_full_bounds()\n",
        "    print(df_preview.head())"
      ],
      "metadata": {
        "id": "hQ2iPOW9QHAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#$C^m$のみが異なる場合"
      ],
      "metadata": {
        "id": "Dypz6_p1SnRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "corr_only_sweep_full_bounds_dpi.py\n",
        "- Robust MVP (r, sigma fixed, C varies) α-sweep.\n",
        "- Calculates bounds from Thm 2 (S(w*)), Thm 6 (Y0), Thm 8 (X_piY).\n",
        "- Includes dpi* calculation.\n",
        "Based on the provided correlation_only script.\n",
        "\"\"\"\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import scipy.linalg as la # Added for phi_and_grad check\n",
        "from scipy.optimize import minimize, Bounds, LinearConstraint # For Y0, X_piY\n",
        "import logging, sys # Added logging\n",
        "\n",
        "# ---------------------------- GLOBALS ----------------------------\n",
        "K, M = 4, 4\n",
        "mu_tilde = 0.03\n",
        "\n",
        "# ---------- optimiser hyper-parameters (Using corr_only values) ---\n",
        "# Original phi_min had it_max=40, lbfgs_m=5. We'll use minimise_phi's defaults.\n",
        "# Need tol_grad for stopping L-BFGS (use a reasonable default)\n",
        "tol_grad = 1e-8\n",
        "# --- Other constants ---\n",
        "INNER_OPT_TOL_FEAS = 1e-9\n",
        "SOLVER_FEAS_TOL    = 1e-7\n",
        "GENTOL             = 1e-9\n",
        "FINITE_DIFF_EPS    = 1e-12\n",
        "\n",
        "# -------------- Fixed parameters --------------\n",
        "r_bar = np.array([0.02, 0.03, 0.04, 0.05])\n",
        "sigma_bar = np.array([0.20, 0.25, 0.30, 0.35])\n",
        "inv_sigma_bar = 1.0 / sigma_bar\n",
        "g_vec = r_bar / sigma_bar\n",
        "\n",
        "# -------------- Correlation setup ----------------------\n",
        "beta_corr = 1 # From original code\n",
        "\n",
        "def block_corr(rho_in, rho_out): # Identical\n",
        "    C = np.full((K, K), rho_out); np.fill_diagonal(C, 1.0)\n",
        "    for i, j in ((0, 1), (2, 3)): C[i, j] = C[j, i] = rho_in\n",
        "    return C\n",
        "C_base = block_corr(0.75, 0.50)\n",
        "C_tilde = [block_corr(0.85, 0.40), block_corr(0.65, 0.40),\n",
        "           block_corr(0.65, 0.60), block_corr(0.85, 0.60)]\n",
        "\n",
        "# ---- blend & SPD-project ----------------------------------------\n",
        "def mix_corr(C0, C1, alpha, beta=0.5, eps=1e-4): # Identical\n",
        "    C = (1 - beta * alpha) * C0 + beta * alpha * C1\n",
        "    try:\n",
        "        eigval, eigvec = np.linalg.eigh(C)\n",
        "    except np.linalg.LinAlgError: # Handle potential convergence issues\n",
        "        # print(f\"Warning: Eigh failed for mix_corr alpha={alpha}. Using fallback.\")\n",
        "        return C0, -np.inf # Return base and signal error\n",
        "    eigval = np.clip(eigval, eps, None)\n",
        "    C_spd = eigvec @ np.diag(eigval) @ eigvec.T\n",
        "    # Ensure diagonal is 1 for correlation matrix\n",
        "    D_diag = np.sqrt(np.diag(C_spd))\n",
        "    if np.any(D_diag <= 1e-10): # Avoid division by zero\n",
        "         # print(f\"Warning: mix_corr resulted in near-zero diagonal for alpha={alpha}\")\n",
        "         # Fallback? Return C0? Or regularized C_spd?\n",
        "         # Let's return regularized C_spd but signal maybe lower quality min_eig\n",
        "         C_spd += np.eye(K) * 1e-8\n",
        "         D_diag = np.sqrt(np.diag(C_spd))\n",
        "         min_eig_val = np.min(np.linalg.eigvalsh(C_spd / np.outer(D_diag, D_diag)))\n",
        "         # Need to return correlation matrix\n",
        "         C_corr = C_spd / np.outer(D_diag, D_diag)\n",
        "         np.fill_diagonal(C_corr, 1.0)\n",
        "         return C_corr, min_eig_val * 0.1 # Penalize lambda_min if fallback used\n",
        "\n",
        "    D_inv = np.diag(1.0 / D_diag)\n",
        "    C_corr = D_inv @ C_spd @ D_inv\n",
        "    np.fill_diagonal(C_corr, 1.0) # Ensure diagonal is exactly 1\n",
        "    return C_corr, float(np.min(eigval)) # Return original min eigenvalue before clipping for info\n",
        "\n",
        "# ---------------------- simplex projection ------------------------\n",
        "def proj_simplex(v): # Identical\n",
        "    v = np.asarray(v) # Ensure numpy array\n",
        "    v = v.clip(min=0.0) # Clip negatives first\n",
        "    if abs(v.sum() - 1) < 1e-10: return v\n",
        "    u = np.sort(v)[::-1]; cssv = np.cumsum(u) - 1\n",
        "    try:\n",
        "        # Handle edge case where all elements are zero after clipping\n",
        "        if cssv[-1] < 0: return np.zeros_like(v) # Or equi-weight? Let's return zeros\n",
        "        rho_candidates = np.where(u - cssv / (np.arange(len(v)) + 1) > 0)[0]\n",
        "        if len(rho_candidates) == 0: # If check doesn't yield index (e.g., near zero input)\n",
        "            # Heuristic: find last element > 0? Or assume rho=0?\n",
        "            # Let's return equi-weight as fallback if rho cannot be found\n",
        "            return np.ones_like(v) / len(v)\n",
        "        rho = rho_candidates[-1]\n",
        "        theta = cssv[rho] / (rho + 1)\n",
        "        return np.maximum(v - theta, 0.0)\n",
        "    except IndexError: return np.ones_like(v) / len(v) # Fallback\n",
        "\n",
        "# ---------------------- parameter builder (corr varies) -----------\n",
        "def build_params_corr_only(alpha):\n",
        "    \"\"\"Returns R(=r_bar repeated), Sigma_m(alpha), V_m(alpha)\"\"\"\n",
        "    R_th = np.tile(r_bar[:, np.newaxis], (1, M))\n",
        "    Sigma_th = np.zeros((K, K, M))\n",
        "    V_th = np.zeros((K, K, M))\n",
        "    lambda_min_corr_log = []\n",
        "    D_sigma_bar = np.diag(sigma_bar)\n",
        "    reg_V = 1e-8; reg_S = 1e-8\n",
        "\n",
        "    for m in range(M):\n",
        "        C_m, lam_min = mix_corr(C_base, C_tilde[m], alpha, beta=beta_corr, eps=1e-5)\n",
        "        if lam_min == -np.inf : raise ValueError(f\"mix_corr failed for alpha={alpha}, m={m}\")\n",
        "        lambda_min_corr_log.append(lam_min)\n",
        "\n",
        "        V_m = D_sigma_bar @ C_m @ D_sigma_bar\n",
        "        min_eig_Vm = np.min(np.linalg.eigvalsh(V_m))\n",
        "        if min_eig_Vm <= reg_V: V_m += np.eye(K) * (abs(min_eig_Vm) + reg_V)\n",
        "        V_th[:, :, m] = V_m\n",
        "\n",
        "        Sigma_th[:, :, m] = V_m + np.outer(r_bar, r_bar)\n",
        "        min_eig_Sm = np.min(np.linalg.eigvalsh(Sigma_th[:, :, m]))\n",
        "        if min_eig_Sm <= reg_S: Sigma_th[:, :, m] += np.eye(K) * (abs(min_eig_Sm) + reg_S)\n",
        "\n",
        "    lambda_min_for_csv = float(min(lambda_min_corr_log)) if lambda_min_corr_log else np.nan\n",
        "\n",
        "    return R_th, Sigma_th, V_th, lambda_min_for_csv\n",
        "\n",
        "# ---------------------- Utility Functions (Y0, X_piY) ---------------\n",
        "# (Identical to previous correct versions, omitted for brevity)\n",
        "def calculate_Y0(R_trial, Sigma_list_trial, mu_tilde_val, k_assets, m_models, rng_y0_pert):\n",
        "    pi_avg_r = np.mean(R_trial, axis=1); k_assets=R_trial.shape[0]; m_models=R_trial.shape[1]\n",
        "    if np.linalg.norm(pi_avg_r) > 1e-6: pi_initial_guess = pi_avg_r / np.linalg.norm(pi_avg_r)\n",
        "    else: pi_initial_guess = np.ones(k_assets) / np.sqrt(k_assets)\n",
        "    max_tries_feas = 10; found_feasible_pi = False; SOLVER_FEAS_TOL=1e-7\n",
        "    constraint_func = lambda pi: pi @ R_trial[:, 0] - mu_tilde_val # Use first column for r_bar\n",
        "    for i_try in range(max_tries_feas):\n",
        "        if constraint_func(pi_initial_guess) >= -SOLVER_FEAS_TOL : found_feasible_pi = True; break\n",
        "        else: current_ret = pi_initial_guess @ R_trial[:, 0]\n",
        "        if current_ret > 1e-9: pi_initial_guess *= (mu_tilde_val / current_ret) * (1.01 + 0.1*i_try)\n",
        "        else: pi_initial_guess += rng_y0_pert.normal(0, 0.1, size=k_assets); norm_pi = np.linalg.norm(pi_initial_guess); pi_initial_guess /= norm_pi if norm_pi > 1e-6 else 1\n",
        "    if not found_feasible_pi: pi_initial_guess = np.ones(k_assets) / k_assets\n",
        "    t_initial_guess = 0.0\n",
        "    for m in range(m_models): t_initial_guess = max(t_initial_guess, pi_initial_guess @ Sigma_list_trial[:,:,m] @ pi_initial_guess)\n",
        "    t_initial_guess = max(1e-6, t_initial_guess)\n",
        "    x_initial = np.concatenate([pi_initial_guess, [t_initial_guess]])\n",
        "    func = lambda x: x[-1]; cons = []\n",
        "    for m in range(m_models): cons.append({'type': 'ineq', 'fun': lambda x, Sm=Sigma_list_trial[:,:,m]: x[-1] - x[:-1] @ Sm @ x[:-1]})\n",
        "    cons.append({'type': 'ineq', 'fun': lambda x, rm=R_trial[:,0]: x[:-1] @ rm - mu_tilde_val})\n",
        "    bounds = [(-np.inf, np.inf)] * k_assets + [(1e-8, np.inf)]\n",
        "    opt_res_Y0 = minimize(func, x_initial, method='SLSQP', bounds=bounds, constraints=cons, options={'ftol': 1e-8, 'disp': False, 'maxiter': 1000})\n",
        "    pi_Y = None; Y0_val = np.nan\n",
        "    if opt_res_Y0.success:\n",
        "        pi_sol, t_sol = opt_res_Y0.x[:-1], opt_res_Y0.x[-1]; feasible = True\n",
        "        min_ret_check = pi_sol @ R_trial[:,0]\n",
        "        max_quad_check = np.max([pi_sol @ Sigma_list_trial[:,:,m] @ pi_sol for m in range(m_models)])\n",
        "        if min_ret_check < mu_tilde_val - SOLVER_FEAS_TOL: feasible = False\n",
        "        if abs(t_sol - max_quad_check) > SOLVER_FEAS_TOL * (1 + abs(t_sol)) + 1e-7 : feasible = False\n",
        "        if feasible: pi_Y = pi_sol; Y0_val = t_sol\n",
        "    return pi_Y, Y0_val\n",
        "\n",
        "def calculate_X_pi_Y(pi_Y, R_trial, Sigma_list_trial, V_list_trial, k_assets, m_models):\n",
        "    if pi_Y is None: return np.nan\n",
        "    v_m_vec = np.array([pi_Y @ V_list_trial[:,:,m] @ pi_Y for m in range(m_models)])\n",
        "    a_m_vec = R_trial[:,0].T @ pi_Y; a_m_vec_rep = np.full(m_models, a_m_vec)\n",
        "    Q_mat = np.outer(a_m_vec_rep, a_m_vec_rep); c_vec = v_m_vec + a_m_vec_rep**2\n",
        "    obj_func = lambda w: w @ Q_mat @ w - c_vec @ w; jac_func = lambda w: 2 * Q_mat @ w - c_vec\n",
        "    bounds_w = Bounds(np.zeros(m_models), np.full(m_models, np.inf))\n",
        "    constraints_w = LinearConstraint(np.ones((1, m_models)), [1.0], [1.0])\n",
        "    w_initial = np.ones(m_models) / m_models\n",
        "    qp_res = minimize(obj_func, w_initial, method='SLSQP', jac=jac_func, bounds=bounds_w, constraints=constraints_w, options={'ftol': 1e-9, 'disp': False})\n",
        "    if qp_res.success:\n",
        "        w_opt_for_X = qp_res.x; w_opt_for_X = np.maximum(0, w_opt_for_X); w_opt_for_X /= np.sum(w_opt_for_X)\n",
        "        var_a_m = 0.0; X_piY_val = w_opt_for_X @ v_m_vec + var_a_m\n",
        "        return max(0, X_piY_val)\n",
        "    else: return np.nan\n",
        "\n",
        "\n",
        "# -------- Φ(w) = gᵀQ⁻¹g  and its gradient ∇Φ(w) ------------------\n",
        "# (Function definition identical to original code)\n",
        "def phi_and_grad(w, Cstack):\n",
        "    # Ensure Cstack elements are well-defined\n",
        "    if any(np.any(np.isnan(C)) or np.any(np.isinf(C)) for C in Cstack):\n",
        "        # print(\"Warning: NaN/Inf in Cstack input to phi_and_grad\")\n",
        "        return np.inf, np.full(len(w), np.nan), None\n",
        "\n",
        "    Q = sum(w[m] * Cstack[m] for m in range(M))\n",
        "    # Check if Q is SPD before solving\n",
        "    try:\n",
        "        # Add regularization for stability\n",
        "        Q_reg = Q + np.eye(K) * 1e-9\n",
        "        # Use Cholesky factorization for solve - more stable for SPD\n",
        "        L = la.cholesky(Q_reg, lower=True)\n",
        "        y = la.solve_triangular(L.T, la.solve_triangular(L, g_vec, lower=True))\n",
        "        # y = np.linalg.solve(Q_reg, g_vec) # Alternative if Cholesky fails\n",
        "        phi = g_vec @ y\n",
        "        grad = -np.array([y @ Cstack[m] @ y for m in range(M)])\n",
        "    except (np.linalg.LinAlgError, ValueError): # Catch solve errors or non-SPD for Cholesky\n",
        "         # Fallback with pseudo-inverse\n",
        "         try:\n",
        "             Q_pinv = np.linalg.pinv(Q_reg if 'Q_reg' in locals() else Q + np.eye(K) * 1e-9)\n",
        "             y = Q_pinv @ g_vec\n",
        "             phi = g_vec @ y\n",
        "             grad = -np.array([y @ Cstack[m] @ y for m in range(M)])\n",
        "         except np.linalg.LinAlgError: # If pseudo-inverse also fails\n",
        "             return np.inf, np.full(len(w), np.nan), None # Indicate failure\n",
        "\n",
        "    return phi, grad, y # Return y as well\n",
        "\n",
        "# -------------- L-BFGS on the simplex (from original code) -------------------\n",
        "# (Function definition identical to original code)\n",
        "def minimise_phi(Cstack, it_max=40, lbfgs_m=5): # Increased it_max slightly\n",
        "    w = np.full(M, 1 / M); s_hist, y_hist = [], []\n",
        "    phi, grad, y = phi_and_grad(w, Cstack)\n",
        "    if np.isnan(grad).any(): return np.inf, w, y, 0 # Initial fail\n",
        "\n",
        "    for it in range(1, it_max + 1):\n",
        "        if np.linalg.norm(proj_simplex(w - grad) - w) < tol_grad: break # Use global tol_grad\n",
        "        q = grad.copy(); alpha_hist = []\n",
        "        for s, y_h in reversed(list(zip(s_hist, y_hist))):\n",
        "            rho = 1.0 / (y_h @ s + 1e-12) # Avoid division by zero\n",
        "            a = rho * (s @ q); alpha_hist.append(a); q -= a * y_h\n",
        "        if s_hist: gamma = (s_hist[-1] @ y_hist[-1]) / (y_hist[-1] @ y_hist[-1] + 1e-12); q *= gamma\n",
        "        for s, y_h, a in zip(s_hist, y_hist, reversed(alpha_hist)):\n",
        "            rho = 1.0 / (y_h @ s + 1e-12); beta = rho * (y_h @ q); q += s * (a - beta)\n",
        "        d = -q; step = 1.0; accepted_step = False\n",
        "        for _ls in range(20): # Line search\n",
        "            w_new = proj_simplex(w + step * d)\n",
        "            # Add try-except around phi_and_grad in line search\n",
        "            try: phi_new, grad_new, y_new = phi_and_grad(w_new, Cstack)\n",
        "            except: phi_new=np.inf; grad_new=None; y_new=None # Handle potential errors\n",
        "            if np.isnan(phi_new) or (grad_new is not None and np.isnan(grad_new).any()): # Check for NaN\n",
        "                 step *= 0.5; continue\n",
        "            # Use slightly more robust Armijo check\n",
        "            if phi_new < phi - 1e-5 * step * max(1e-9, grad @ d): # Adjust Armijo param if needed\n",
        "                accepted_step = True; break\n",
        "            step *= 0.5\n",
        "        if not accepted_step: break\n",
        "        s_k = w_new - w; y_k = grad_new - grad\n",
        "        if y_k @ s_k > 1e-12:\n",
        "            s_hist.append(s_k); y_hist.append(y_k)\n",
        "            if len(s_hist) > lbfgs_m: s_hist.pop(0); y_hist.pop(0)\n",
        "        w, phi, grad, y = w_new, phi_new, grad_new, y_new\n",
        "    # Return minimized phi, w, y, and iterations\n",
        "    return phi, w, y, it\n",
        "\n",
        "\n",
        "# --------------------- CALCULATE BOUNDS AND SR (Corr only case) -----------------------\n",
        "def calculate_bounds_and_sr_corr_only(pi_star, w_star, H_star_val, R_common, Sigma_alpha, V_alpha):\n",
        "    \"\"\"Calculate SR_rob, B_U1 (S(w*)), B_U2 (rho_max).\"\"\"\n",
        "    SR_rob_val, B_U1_val, B_U2_val = np.nan, np.nan, np.nan\n",
        "    if pi_star is None or w_star is None or np.isnan(H_star_val): return SR_rob_val, B_U1_val, B_U2_val\n",
        "\n",
        "    # SR_rob: Use H_star_val = mu^2 / phi* as denominator^2\n",
        "    r_bar_ws = R_common[:,0] # Since R is common\n",
        "    numerator_sr = pi_star @ r_bar_ws # Should be mu_tilde by construction of pi_star\n",
        "    denominator_sr_sq = H_star_val\n",
        "    if denominator_sr_sq > 1e-12: SR_rob_val = numerator_sr / np.sqrt(denominator_sr_sq)\n",
        "    elif abs(numerator_sr) < GENTOL: SR_rob_val = 0.0\n",
        "\n",
        "    # B_U1 = sqrt(S(w*))\n",
        "    # V^w = sum w_m V^m = D(sig_bar) (sum w_m C^m) D(sig_bar)\n",
        "    C_w_star = np.sum(np.fromiter((w_star[m] * (la.inv(np.diag(sigma_bar)) @ V_alpha[:,:,m] @ la.inv(np.diag(sigma_bar))) for m in range(M)), dtype=object)) # Get weighted C\n",
        "    Vw_star = np.diag(sigma_bar) @ C_w_star @ np.diag(sigma_bar)\n",
        "    try:\n",
        "        Vw_star_inv = np.linalg.inv(Vw_star + np.eye(K)*1e-10); s_w_star_num = r_bar_ws @ Vw_star_inv @ r_bar_ws\n",
        "        if s_w_star_num < -GENTOL: s_w_star_num = 0; B_U1_val = np.sqrt(s_w_star_num)\n",
        "    except np.linalg.LinAlgError: B_U1_val = np.nan\n",
        "\n",
        "    # B_U2 = sqrt(rho_max / (1-rho_max))\n",
        "    rho_m_vals = np.zeros(M); all_rho_m_ok = True\n",
        "    for m in range(M):\n",
        "        try: Sigma_m_inv = np.linalg.inv(Sigma_alpha[:,:,m] + np.eye(K)*1e-10); rho_m_vals[m] = r_bar_ws @ Sigma_m_inv @ r_bar_ws\n",
        "        except np.linalg.LinAlgError: all_rho_m_ok = False; break\n",
        "    if all_rho_m_ok:\n",
        "        rho_max_val = np.max(rho_m_vals); rho_max_val = min(rho_max_val, 1.0 - 1e-12)\n",
        "        if rho_max_val < 0: B_U2_val = np.nan\n",
        "        else: B_U2_val = np.sqrt(rho_max_val / (1.0 - rho_max_val))\n",
        "    else: B_U2_val = np.nan\n",
        "    return SR_rob_val, B_U1_val, B_U2_val\n",
        "\n",
        "# ------------------------ FINITE DIFFERENCE HELPER -----------------------\n",
        "def finite_diff_vec(v_p, v_m, h, length):\n",
        "    if v_p is None or v_m is None or h is None or np.isnan(h) or abs(h) < FINITE_DIFF_EPS: return np.full(length, np.nan)\n",
        "    actual_h = h if abs(h) > FINITE_DIFF_EPS else np.sign(h)*FINITE_DIFF_EPS if h!=0 else FINITE_DIFF_EPS\n",
        "    return (v_p - v_m) / (2 * actual_h)\n",
        "\n",
        "# ------------------------ α-sweep main computation -----------------------\n",
        "def run_sweep_corr_only_full_bounds(out_csv=\"corr_only_sweep_full_bounds_dpi.csv\"):\n",
        "    log = logging.getLogger(\"sweep_corr\")\n",
        "    log.propagate = False\n",
        "    log.setLevel(logging.INFO)\n",
        "    if not log.handlers: log.addHandler(logging.StreamHandler(sys.stdout))\n",
        "    log.info(\"========== Correlation Only α-Sweep Full Bounds with dpi* START ==========\")\n",
        "\n",
        "    col_w   = [f\"w*_m{m}\" for m in range(M)]; col_pi  = [f\"pi*_k{k}\" for k in range(K)]\n",
        "    col_ret = [f\"cstr_ret_m{m}\" for m in range(M)]; col_lam = [f\"lam_m{m}\" for m in range(M)]\n",
        "    col_dpi = [f\"dpi*_k{k}\" for k in range(K)]\n",
        "    columns = ([\"alpha\", \"H_star\", \"supp_w\", \"lambda_min_corr\", \"iterations\", # lambda_min from mix_corr\n",
        "                \"SR_rob\", \"SR_Bound_Sw\", \"SR_Bound_rho_max\",\n",
        "                \"SR_Bound_Y0\", \"SR_Bound_XpiY\",\n",
        "                \"Y0_val\", \"XpiY_val\"]\n",
        "               + col_w + col_pi + col_ret + col_lam + col_dpi)\n",
        "\n",
        "    rows, cache = [], {}\n",
        "    rng_y0 = np.random.default_rng(34567)\n",
        "    t0 = datetime.now()\n",
        "    y0_fail_count = 0; xpiy_fail_count = 0; phi_fail_count = 0\n",
        "\n",
        "    # --- Define get helper for caching pi_star ---\n",
        "    def get_corr_only_pi(alpha_val):\n",
        "        cache_key = alpha_val\n",
        "        if cache_key not in cache:\n",
        "            try:\n",
        "                R_a, Sigma_a, V_a, lambda_min_a = build_params_corr_only(alpha_val)\n",
        "                Cstack_a = [(la.inv(np.diag(sigma_bar)) @ V_a[:,:,m] @ la.inv(np.diag(sigma_bar))) for m in range(M)] # Extract C_m from V_m\n",
        "                phi_star_a, w_star_a, y_star_a, iters_a = minimise_phi(Cstack_a)\n",
        "                if np.isinf(phi_star_a): raise ValueError(\"minimise_phi failed\")\n",
        "                pi_star_a = (mu_tilde / phi_star_a) * inv_sigma_bar * y_star_a\n",
        "                cache[cache_key] = {\"pi_star\": pi_star_a}\n",
        "            except Exception as e: cache[cache_key] = None\n",
        "        return cache[cache_key]\n",
        "    # --- End get helper ---\n",
        "\n",
        "    for idx, alpha in enumerate(ALPHA_GRID):\n",
        "        if (idx * 100 // N_ALPHA) > ((idx - 1) * 100 // N_ALPHA):\n",
        "             log.info(f\"Progress: {idx * 100 / N_ALPHA:.0f}% (α = {alpha:.5f})\")\n",
        "\n",
        "        try:\n",
        "            R_th, Sigma_th, V_th, lambda_min_val = build_params_corr_only(alpha)\n",
        "            # Calculate Cstack for minimise_phi\n",
        "            Cstack = []\n",
        "            for m in range(M):\n",
        "                # Extract C_m from V_m = D C_m D\n",
        "                D_inv = np.diag(inv_sigma_bar)\n",
        "                C_m = D_inv @ V_th[:,:,m] @ D_inv\n",
        "                # Optional: Re-normalize C_m to ensure perfect correlation matrix properties?\n",
        "                # diag_C = np.sqrt(np.diag(C_m))\n",
        "                # if np.any(diag_C <= 1e-10): raise ValueError(\"Zero diag in extracted C_m\")\n",
        "                # C_m = np.diag(1.0/diag_C) @ C_m @ np.diag(1.0/diag_C)\n",
        "                # np.fill_diagonal(C_m, 1.0)\n",
        "                Cstack.append(C_m)\n",
        "\n",
        "            phi_star, w_star, y_star, nit = minimise_phi(Cstack)\n",
        "            if np.isinf(phi_star): raise ValueError(\"minimise_phi failed\")\n",
        "\n",
        "            H_star = mu_tilde ** 2 / phi_star\n",
        "            pi_star = (mu_tilde / phi_star) * inv_sigma_bar * y_star\n",
        "\n",
        "        except Exception as e:\n",
        "            log.warning(f\"Skipping alpha = {alpha:.5f} due to error in main calc: {e}\")\n",
        "            phi_fail_count += 1\n",
        "            continue\n",
        "\n",
        "        if alpha not in cache: cache[alpha] = {\"pi_star\": pi_star}\n",
        "\n",
        "        SR_rob, B_U1, B_U2 = calculate_bounds_and_sr_corr_only(pi_star, w_star, H_star, R_th, Sigma_th, V_th)\n",
        "        pi_Y, Y0_val = calculate_Y0(R_th, Sigma_th, mu_tilde, K, M, rng_y0)\n",
        "        if pi_Y is None or np.isnan(Y0_val): y0_fail_count += 1\n",
        "        XpiY_val = calculate_X_pi_Y(pi_Y, R_th, Sigma_th, V_th, K, M)\n",
        "        if pi_Y is not None and np.isnan(XpiY_val): xpiy_fail_count += 1\n",
        "        B_L1 = mu_tilde / np.sqrt(Y0_val) if Y0_val is not None and not np.isnan(Y0_val) and Y0_val > 1e-12 else np.nan\n",
        "        B_L2 = mu_tilde / np.sqrt(XpiY_val) if XpiY_val is not None and not np.isnan(XpiY_val) and XpiY_val > 1e-12 else np.nan\n",
        "\n",
        "        # Calculate dpi* using finite difference and cache\n",
        "        dpi_star = np.full(K, np.nan); prev_alpha = ALPHA_GRID[idx - 1] if idx > 0 else None\n",
        "        next_alpha = ALPHA_GRID[idx + 1] if idx < N_ALPHA - 1 else None; h = np.nan; pi_p, pi_m = None, None\n",
        "        if prev_alpha is not None and next_alpha is not None:\n",
        "            h = min(alpha - prev_alpha, next_alpha - alpha); h = max(h, FINITE_DIFF_EPS)\n",
        "            res_p = get_corr_only_pi(alpha + h); res_m = get_corr_only_pi(alpha - h)\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / (2*h)\n",
        "        elif prev_alpha is None and next_alpha is not None:\n",
        "            h = next_alpha - alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_p = get_corr_only_pi(next_alpha); pi_m = pi_star\n",
        "            if res_p is not None: pi_p = res_p[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "        elif next_alpha is None and prev_alpha is not None:\n",
        "            h = alpha - prev_alpha\n",
        "            if h >= FINITE_DIFF_EPS: res_m = get_corr_only_pi(prev_alpha); pi_p = pi_star\n",
        "            if res_m is not None: pi_m = res_m[\"pi_star\"]\n",
        "            if pi_p is not None and pi_m is not None: dpi_star = (pi_p - pi_m) / h\n",
        "\n",
        "        # Format other outputs\n",
        "        cstr_ret = np.full(M, mu_tilde); lam_vec = np.full(M, np.nan)\n",
        "\n",
        "        # Append row\n",
        "        row_data = {\"alpha\": alpha, \"H_star\": H_star, \"supp_w\": int((w_star > 1e-6).sum()),\n",
        "                    \"lambda_min_corr\": lambda_min_val, \"iterations\": nit, \"SR_rob\": SR_rob,\n",
        "                    \"SR_Bound_Sw\": B_U1, \"SR_Bound_rho_max\": B_U2, \"SR_Bound_Y0\": B_L1, \"SR_Bound_XpiY\": B_L2,\n",
        "                    \"Y0_val\": Y0_val, \"XpiY_val\": XpiY_val}\n",
        "        row_data.update({f\"w*_m{m}\": w_star[m] for m in range(M)})\n",
        "        row_data.update({f\"pi*_k{k}\": pi_star[k] for k in range(K)})\n",
        "        row_data.update({f\"cstr_ret_m{m}\": cstr_ret[m] for m in range(M)})\n",
        "        row_data.update({f\"lam_m{m}\": lam_vec[m] for m in range(M)})\n",
        "        row_data.update({f\"dpi*_k{k}\": dpi_star[k] for k in range(K)})\n",
        "        rows.append(row_data)\n",
        "\n",
        "    df = pd.DataFrame(rows, columns=columns)\n",
        "    df.to_csv(out_csv, index=False, float_format=\"%.10g\")\n",
        "    log.info(f\"CSV written to {out_csv}  (elapsed {(datetime.now() - t0).total_seconds():.1f}s)\")\n",
        "    log.info(f\"Total Phi Minimization Fails: {phi_fail_count}, Y0 Fails: {y0_fail_count}, XpiY Fails: {xpiy_fail_count}\")\n",
        "    return df\n",
        "\n",
        "# --------------------------- MAIN --------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Define ALPHA_MIN, ALPHA_MAX, N_ALPHA before calling\n",
        "    ALPHA_MIN = 0.01\n",
        "    ALPHA_MAX = 1.0\n",
        "    N_ALPHA = 101 # Reduce N_ALPHA for testing\n",
        "    ALPHA_GRID = np.linspace(ALPHA_MIN, ALPHA_MAX, N_ALPHA)\n",
        "\n",
        "    df_preview = run_sweep_corr_only_full_bounds()\n",
        "    print(df_preview.head())"
      ],
      "metadata": {
        "id": "RqTT1O5NQHny"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}