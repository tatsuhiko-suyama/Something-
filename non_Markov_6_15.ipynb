{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tatsuhiko-suyama/Something-/blob/main/non_Markov_6_15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHoAKnrx4sM1",
        "outputId": "b2bfda50-8336-4513-dbbd-307c5305e318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting japanize_matplotlib\n",
            "  Downloading japanize-matplotlib-1.1.3.tar.gz (4.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from japanize_matplotlib) (3.6.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (9.2.0)\n",
            "Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.23.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (23.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (1.4.4)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->japanize_matplotlib) (0.11.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib->japanize_matplotlib) (1.14.0)\n",
            "Building wheels for collected packages: japanize_matplotlib\n",
            "  Building wheel for japanize_matplotlib (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for japanize_matplotlib: filename=japanize_matplotlib-1.1.3-py3-none-any.whl size=4120258 sha256=b5c5621f5c3f05810a2a414a399bb37fc375a0a3c5793f3ba44f2b48e3662667\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/6b/86/8d53dd07a93ebf907e5ba60f380ee2f932880c25f7a55026e4\n",
            "Successfully built japanize_matplotlib\n",
            "Installing collected packages: japanize_matplotlib\n",
            "Successfully installed japanize_matplotlib-1.1.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: plotly in /usr/local/lib/python3.9/dist-packages (5.22.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.9/dist-packages (from plotly) (8.3.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install japanize_matplotlib\n",
        "!pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "code",
        "id": "7EGFP-MW4sM4"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ストラングル 3\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.stats import norm\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 5# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "\n",
        "\n",
        "def BS_price( S, K, r, sigma, T, payoff):\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    if payoff == 'call':\n",
        "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "    elif payoff == 'put':\n",
        "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
        "    else:\n",
        "        raise ValueError('payoff must be either \"call\" or \"put\"')\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "\n",
        "\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    payoff='bull'\n",
        "    # 支払い条件に応じたb_n, c_nの計算\n",
        "    if payoff == 'call':\n",
        "        b_n = torch.clamp(stock_price - strike, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle':\n",
        "        b_n = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'bull':\n",
        "        b_n = torch.clamp(stock_price - 80, min=0).cuda() - torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'batafrei':\n",
        "        b_n = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle_batafrei':\n",
        "        strangle = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        batafrei = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = strangle + batafrei\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'put_bull':\n",
        "        put = torch.clamp(80 - stock_price, min=0).cuda()\n",
        "        bull = torch.clamp(stock_price - 80, min=0).cuda() - torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = put + bull\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle_2batafrei':\n",
        "        strangle = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        batafrei = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = strangle + 2 * batafrei\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'M_type':\n",
        "        put=torch.clamp(80-stock_price, min=0).cuda()\n",
        "        batafrei=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "        call=torch.clamp(stock_price-120, min=0).cuda()\n",
        "        b_n=-put-2*batafrei-call+40\n",
        "        c_n=b_n**2\n",
        "\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZWf9DPp7mwd",
        "outputId": "aae7ea69-e9a4-4536-e385-dc72bfaa409b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[26.1553924 , 20.22449372],\n",
              "       [21.52870986, 19.10092681],\n",
              "       [19.17347615, 19.0384264 ],\n",
              "       [20.01343232, 18.19847024],\n",
              "       [31.3017807 ,  6.91012185],\n",
              "       [14.93126622,  0.        ],\n",
              "       [14.93126622,  0.        ],\n",
              "       [ 0.        ,  0.        ],\n",
              "       [50.30437758, 14.93126622],\n",
              "       [14.93126622,  0.        ],\n",
              "       [14.93126622,  0.        ],\n",
              "       [ 0.        ,  0.        ],\n",
              "       [14.93126622,  0.        ],\n",
              "       [ 0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ],\n",
              "       [ 0.        ,  0.        ]])"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Call_T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w5G0P05g4sM6",
        "outputId": "16771ddf-ec87-411d-9c6a-432ad19191db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.2"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILw4GeAl5TqC",
        "outputId": "7de96270-4132-40a7-f4e1-b01229bce847"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "92xdCcjs4sM7",
        "outputId": "3651cd63-30e2-4e94-d55a-673aaeb32457"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.25110906, 0.48979592, 0.25909502])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "param_to_prob(mu=0.03, sigma=0.25,nu=nu,zeta=zeta,dt=dt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "qt1HeM_u4sM8",
        "outputId": "5fe75a8a-3af0-4787-e2ca-634d42b6ce52"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "初期コスト 18.387517628638843\n",
            "0 4.429898471811612\n",
            "1000 10.362193751159168\n",
            "2000 10.389088484416845\n",
            "3000 10.389239756284553\n",
            "4000 10.391903076040649\n",
            "5000 10.392564980992518\n",
            "6000 10.379279207568175\n",
            "7000 10.437886214032517\n",
            "8000 10.437892121408538\n",
            "9000 10.437841095123702\n",
            "10000 10.437900153713883\n",
            "11000 10.437901032415596\n",
            "12000 10.437902266285903\n",
            "13000 10.437901894645222\n",
            "14000 10.437904129630397\n",
            "15000 10.437905668724795\n",
            "16000 10.437899332385712\n",
            "17000 10.4378967900941\n",
            "18000 10.437905982958853\n",
            "19000 10.43789026909559\n",
            "20000 10.437868962451432\n",
            "21000 10.437906094691925\n",
            "22000 10.43790613626976\n",
            "23000 10.43790593344221\n",
            "24000 10.437906325363542\n",
            "25000 10.429837459801377\n",
            "26000 10.429825112623973\n",
            "27000 10.429837474118926\n",
            "28000 10.42982536043445\n",
            "29000 10.429837475535294\n",
            "30000 10.42983745497952\n",
            "31000 10.429837469292522\n",
            "32000 10.429837473223472\n",
            "33000 10.429837419663954\n",
            "34000 10.429837472600582\n",
            "35000 10.429837474997157\n",
            "36000 10.429836800389069\n",
            "37000 10.43118807005203\n",
            "38000 10.4311888013994\n",
            "39000 10.431188798221001\n",
            "40000 10.431170742688266\n",
            "41000 10.431178468839619\n",
            "42000 10.431188821944943\n",
            "43000 10.43118750737068\n",
            "44000 10.431188813058156\n",
            "45000 10.431188827690562\n",
            "46000 10.43122162078538\n",
            "47000 10.431221621617397\n",
            "48000 10.43122159104189\n",
            "49000 10.431220895805268\n",
            "50000 10.431221619929829\n",
            "51000 10.431221623272847\n",
            "52000 10.43122161661205\n",
            "53000 10.431221623662509\n",
            "54000 10.431221624051602\n",
            "55000 10.431220215254882\n",
            "56000 10.43122162278678\n",
            "57000 10.431221568543435\n",
            "58000 10.431221582278283\n",
            "59000 10.431221621669465\n",
            "60000 10.431221623352428\n",
            "61000 10.431221623998681\n",
            "62000 10.431221312184107\n",
            "63000 10.431221623517501\n",
            "64000 10.431219498365977\n",
            "65000 10.431202800419271\n",
            "66000 10.431221156610718\n"
          ]
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ストラングル 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =np.arange(141,150,1)\n",
        "strike_range=[200]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #init_cost= BS_price(100,strike,0,0.3,1,'call')\n",
        "    #init_cost= BS_price(100,80,0,0.3,1,'call')+BS_price(100,120,0,0.3,1,'call')-20\n",
        "    #init_cost =BS_price(100,80,0,0.3,1,'call')-BS_price(100,120,0,0.3,1,'call')\n",
        "    #init_cost =BS_price(100,80,0,0.3,1,'call')-2*BS_price(100,100,0,0.3,1,'call')+BS_price(100,120,0,0.3,1,'call')\n",
        "    def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "      stock_price=np.array(S_0)\n",
        "      for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "      return stock_price\n",
        "    payoff='bull'\n",
        "    if payoff == 'call':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    elif payoff == 'strangle':\n",
        "      Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'bull':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'batafrei':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'strangle_batafrei':\n",
        "      strangle=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=strangle+batafrei\n",
        "    elif payoff == 'put_bull':\n",
        "      put=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\n",
        "      bull=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=put+bull\n",
        "    elif payoff == 'strangle_2batafrei':\n",
        "      strangle=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=strangle+2*batafrei\n",
        "    elif payoff == 'M_type':\n",
        "      put=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      call=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=-put-2*batafrei-call+40\n",
        "    risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "\n",
        "\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "      Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    print('初期コスト',init_cost)\n",
        "    def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "      stock_price=np.array(S_0)\n",
        "      for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "      return stock_price\n",
        "\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 2**6\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5*2\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        if epoch % 1000==0:\n",
        "            print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7MBKWO4_0bZy",
        "outputId": "527a9c12-b342-4805-eb4d-70b5efa40d8a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "13.173790908675008"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YuDjZ-I6BRHN"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ストラングル 3\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from scipy.stats import norm\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 5# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "\n",
        "\n",
        "def BS_price( S, K, r, sigma, T, payoff):\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma ** 2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    if payoff == 'call':\n",
        "        return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "    elif payoff == 'put':\n",
        "        return K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
        "    else:\n",
        "        raise ValueError('payoff must be either \"call\" or \"put\"')\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "\n",
        "\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    payoff='put_bull'\n",
        "    # 支払い条件に応じたb_n, c_nの計算\n",
        "    if payoff == 'call':\n",
        "        b_n = torch.clamp(stock_price - strike, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle':\n",
        "        b_n = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'bull':\n",
        "        b_n = torch.clamp(stock_price - 80, min=0).cuda() - torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'batafrei':\n",
        "        b_n = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle_batafrei':\n",
        "        strangle = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        batafrei = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = strangle + batafrei\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'put_bull':\n",
        "        put = torch.clamp(80 - stock_price, min=0).cuda()\n",
        "        bull = torch.clamp(stock_price - 80, min=0).cuda() - torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = put + bull\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'strangle_2batafrei':\n",
        "        strangle = torch.clamp(80 - stock_price, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        batafrei = torch.clamp(stock_price - 80, min=0).cuda() - 2 * torch.clamp(stock_price - 100, min=0).cuda() + torch.clamp(stock_price - 120, min=0).cuda()\n",
        "        b_n = strangle + 2 * batafrei\n",
        "        c_n = b_n ** 2\n",
        "    elif payoff == 'M_type':\n",
        "        put=torch.clamp(80-stock_price, min=0).cuda()\n",
        "        batafrei=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "        call=torch.clamp(stock_price-120, min=0).cuda()\n",
        "        b_n=-put-2*batafrei-call+40\n",
        "        c_n=b_n**2\n",
        "\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "QW96gAtL0jWE",
        "outputId": "dcf6edab-b45d-40dc-becb-3a7dd152f55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0 6.724261884596444\n",
            "1000 18.026580704065964\n",
            "2000 18.02762104085849\n",
            "3000 18.028923594923015\n",
            "4000 18.02928164720055\n",
            "5000 18.029331431586513\n",
            "6000 18.028862744934543\n",
            "7000 18.02909664061184\n",
            "8000 18.029124502836794\n",
            "9000 18.040437892544162\n",
            "10000 18.04602262939619\n",
            "11000 18.046021696135483\n",
            "12000 18.04853786942357\n",
            "13000 18.0485003821168\n",
            "14000 18.048635257059004\n",
            "15000 18.048629589078132\n",
            "16000 18.04863461051258\n",
            "17000 18.04864011727534\n",
            "18000 18.048572683558348\n",
            "19000 18.04864205360559\n",
            "20000 18.04858915472431\n",
            "21000 18.048657699767773\n",
            "22000 18.04865954908098\n",
            "23000 18.04866040155855\n",
            "24000 18.04853453062816\n",
            "25000 18.04866057110962\n",
            "26000 18.048417660667212\n",
            "27000 18.048658208800248\n",
            "28000 18.048660061385533\n",
            "29000 18.04864516446696\n",
            "30000 18.04841598247424\n",
            "31000 18.0484171888466\n",
            "32000 18.04865786831533\n",
            "33000 18.048660692907845\n",
            "34000 17.953288057335953\n",
            "35000 17.95329016759223\n",
            "36000 17.953288187844407\n",
            "37000 17.953226012888592\n",
            "38000 17.95328771343293\n",
            "39000 17.95328993907333\n",
            "40000 17.95328999168629\n",
            "41000 17.953289002112626\n",
            "42000 17.95328969901658\n",
            "43000 17.953289847204758\n",
            "44000 17.88840731299888\n",
            "45000 17.888491781776167\n",
            "46000 17.88848833772039\n",
            "47000 17.888494265241604\n",
            "48000 17.888494251892382\n",
            "49000 17.888491849611455\n",
            "50000 17.888404989553408\n",
            "51000 17.88840746980071\n",
            "52000 17.968912855356166\n",
            "53000 17.968663610055785\n",
            "54000 17.968668268298416\n",
            "55000 17.968625753834203\n",
            "56000 17.968665936541242\n",
            "57000 17.96862154396314\n",
            "58000 17.968666471815936\n",
            "59000 17.968668603470007\n",
            "60000 17.968668254154124\n",
            "61000 17.968910283516266\n",
            "62000 17.968910532528866\n",
            "63000 17.96891056790264\n",
            "64000 17.968910585487208\n",
            "65000 17.968910508951353\n",
            "66000 17.96891033752263\n",
            "67000 17.96891056927666\n",
            "68000 17.968910647649523\n",
            "69000 17.968909647408054\n",
            "70000 17.968910634629424\n",
            "71000 17.968910660690597\n",
            "72000 17.96891053933848\n",
            "73000 17.968910670042703\n",
            "74000 17.96890843456913\n",
            "75000 17.968902283763498\n",
            "76000 17.968910637559816\n",
            "77000 17.968910094881437\n",
            "78000 17.96891054000872\n",
            "79000 17.968910332117787\n",
            "80000 17.968910319090583\n",
            "81000 17.968668569058252\n",
            "82000 17.968683219408092\n",
            "83000 17.96868239859384\n",
            "84000 17.968735101697007\n",
            "85000 17.96873514076856\n",
            "86000 17.968910555823584\n",
            "87000 17.968910653715113\n",
            "88000 17.968910658751724\n",
            "89000 17.968910654915533\n",
            "90000 17.968910666635168\n",
            "91000 17.968910596819057\n",
            "92000 17.96891065606883\n",
            "93000 17.96891066463303\n",
            "94000 17.968910665699468\n",
            "95000 17.968910644030473\n",
            "96000 17.96891035310091\n",
            "97000 17.96891067150227\n",
            "98000 17.968910643420713\n",
            "99000 17.96891066569492\n",
            "処理時間 : 3762.084180649,strike : 200000,loss : 18.048660700788332\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": 0,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 200000.0,\n        \"max\": 200000.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          200000.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 1,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 33236.0,\n        \"max\": 33236.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          33236.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 2,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 8.182589442991053e-12,\n        \"max\": 8.182589442991053e-12,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          8.182589442991053e-12\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 3,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.3957270570080601,\n        \"max\": 0.3957270570080601,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.3957270570080601\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 4,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 18.048660700788332,\n        \"max\": 18.048660700788332,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          18.048660700788332\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 5,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 3762.0,\n        \"max\": 3762.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          3762.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": 6,\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.0,\n        \"max\": 0.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-f8b560d8-45e8-462f-bfdf-9400764eeedc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200000.0</td>\n",
              "      <td>33236.0</td>\n",
              "      <td>8.182589e-12</td>\n",
              "      <td>0.395727</td>\n",
              "      <td>18.048661</td>\n",
              "      <td>3762.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f8b560d8-45e8-462f-bfdf-9400764eeedc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f8b560d8-45e8-462f-bfdf-9400764eeedc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f8b560d8-45e8-462f-bfdf-9400764eeedc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_4a7b3a9d-0bbc-441e-9c0a-1b428b4eab56\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a7b3a9d-0bbc-441e-9c0a-1b428b4eab56 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          0        1             2         3          4       5    6\n",
              "0  200000.0  33236.0  8.182589e-12  0.395727  18.048661  3762.0  0.0"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ストラングル 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =np.arange(141,150,1)\n",
        "strike_range=[200000]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #init_cost= BS_price(100,strike,0,0.3,1,'call')\n",
        "    #init_cost= BS_price(100,80,0,0.3,1,'call')+BS_price(100,120,0,0.3,1,'call')-20\n",
        "    #init_cost =BS_price(100,80,0,0.3,1,'call')-BS_price(100,120,0,0.3,1,'call')\n",
        "    #init_cost =BS_price(100,80,0,0.3,1,'call')-2*BS_price(100,100,0,0.3,1,'call')+BS_price(100,120,0,0.3,1,'call')\n",
        "    def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "      stock_price=np.array(S_0)\n",
        "      for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "      return stock_price\n",
        "    payoff='put_bull'\n",
        "    if payoff == 'call':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    elif payoff == 'strangle':\n",
        "      Call_T=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'bull':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'batafrei':\n",
        "      Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    elif payoff == 'strangle_batafrei':\n",
        "      strangle=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=strangle+batafrei\n",
        "    elif payoff == 'put_bull':\n",
        "      put=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\n",
        "      bull=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=put+bull\n",
        "    elif payoff == 'strangle_2batafrei':\n",
        "      strangle=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=strangle+2*batafrei\n",
        "    elif payoff == 'M_type':\n",
        "      put=np.maximum(80-stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\n",
        "      batafrei=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-2*np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)+np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      call=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "      Call_T=-put-2*batafrei-call+40\n",
        "    risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "\n",
        "\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "      Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "      stock_price=np.array(S_0)\n",
        "      for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "      return stock_price\n",
        "\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 2**6\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        if epoch % 1000==0:\n",
        "            print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'/content/drive/MyDrive/MVH_NN/nonMarkov/hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'/content/drive/MyDrive/MVH_NN/nonMarkov/hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIrZyiyF7YGv",
        "outputId": "bd6da825-ccc7-48fa-d784-fc33c6ce8445"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([26.1553924 , 20.22449372])"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "init_cost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdajx5M64sM9"
      },
      "outputs": [],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ブルスプレッド 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =np.arange(90,180,10)\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 2**8\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5*2\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUU-WFQ94sM-"
      },
      "outputs": [],
      "source": [
        "#@title 関数 バタフライスプレッド 3\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 3 # @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    #b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWCp5jNE4sM-",
        "outputId": "9d3bbb30-1150-4711-f778-71a625288861"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 1438.1684654860292,strike : 1000,loss : 78.28983347090555\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1000.0</td>\n",
              "      <td>99692.0</td>\n",
              "      <td>7.447706e-14</td>\n",
              "      <td>0.067658</td>\n",
              "      <td>78.289833</td>\n",
              "      <td>1438.0</td>\n",
              "      <td>7.105427e-15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0        1             2         3          4       5             6\n",
              "0  1000.0  99692.0  7.447706e-14  0.067658  78.289833  1438.0  7.105427e-15"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた バタフライスプレッド 3\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[1000]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        -2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "itidA4HM4sM_"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ストラングル 4\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 4# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWYlKZM84sM_",
        "outputId": "ce26d178-6463-42e1-c793-8ce16f84bbfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2506.0909193619154,strike : 20,loss : 35.928793372686314\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20.0</td>\n",
              "      <td>99401.0</td>\n",
              "      <td>1.402683e-14</td>\n",
              "      <td>0.101557</td>\n",
              "      <td>35.928793</td>\n",
              "      <td>2506.0</td>\n",
              "      <td>1.463624e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0        1             2         3          4       5             6\n",
              "0  20.0  99401.0  1.402683e-14  0.101557  35.928793  2506.0  1.463624e-08"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ストラングル 4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[20]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLbjaO3S4sNA"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ブルスプレッド 4\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 4# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    #b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcP_L4ly4sNA",
        "outputId": "a047b956-ad37-4a18-c6c8-8053b08d4d9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2837.2500436999835,strike : 200,loss : 18.650189375033676\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>200.0</td>\n",
              "      <td>73253.0</td>\n",
              "      <td>6.262376e-12</td>\n",
              "      <td>0.527502</td>\n",
              "      <td>18.650189</td>\n",
              "      <td>2837.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0        1             2         3          4       5    6\n",
              "0  200.0  73253.0  6.262376e-12  0.527502  18.650189  2837.0  0.0"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ブルスプレッド 4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[200]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        -np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p_mzFiSb4sNB"
      },
      "outputs": [],
      "source": [
        "#@title 関数 バタフライスプレッド 4\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 4# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    #b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cpoSe6qY4sNB",
        "outputId": "fcaf7777-e78e-47f6-f746-9e8fecc62275"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2388.936821816009,strike : 2000,loss : 39.11137281954801\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000.0</td>\n",
              "      <td>99999.0</td>\n",
              "      <td>9.582801e-11</td>\n",
              "      <td>0.001715</td>\n",
              "      <td>39.111373</td>\n",
              "      <td>2388.0</td>\n",
              "      <td>4.167922e-08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0        1             2         3          4       5             6\n",
              "0  2000.0  99999.0  9.582801e-11  0.001715  39.111373  2388.0  4.167922e-08"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた バタフライスプレッド 4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[2000]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        -2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params =np.array([[0.07, 0.35], [0.03, 0.25],[0.07, 0.25], [0.03, 0.35]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.0001) for net in nets]\n",
        "\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fqC1DP8R4sNC"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ストラングル 5\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 5# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbRIBcxn4sNC",
        "outputId": "0bfb7dfd-9931-4b98-8d29-ad33b9aa56b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2417.4305912000127,strike : 30,loss : 22.967957356786627\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>30.0</td>\n",
              "      <td>19926.0</td>\n",
              "      <td>1.036981e-08</td>\n",
              "      <td>0.129152</td>\n",
              "      <td>22.967957</td>\n",
              "      <td>2417.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      0        1             2         3          4       5    6\n",
              "0  30.0  19926.0  1.036981e-08  0.129152  22.967957  2417.0  0.0"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ストラングル 5\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[30]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vPr9FfNt4sND"
      },
      "outputs": [],
      "source": [
        "#@title 関数 ブルスプレッド 5\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 5# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    #b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IPTOjEo84sND",
        "outputId": "c40aa1cf-f9e4-42e2-d01d-b22cad94ff7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2322.4754613419645,strike : 300,loss : 10.248355588513107\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>300.0</td>\n",
              "      <td>52718.0</td>\n",
              "      <td>1.009002e-11</td>\n",
              "      <td>0.546007</td>\n",
              "      <td>10.248356</td>\n",
              "      <td>2322.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       0        1             2         3          4       5    6\n",
              "0  300.0  52718.0  1.009002e-11  0.546007  10.248356  2322.0  0.0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた ブルスプレッド 5\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[300]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        -np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        #+np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zRXS7sru4sNE"
      },
      "outputs": [],
      "source": [
        "#@title 関数 バタフライスプレッド 5\n",
        "\n",
        "import japanize_matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "import torch\n",
        "torch.set_default_dtype(torch.double)\n",
        "import numpy as np\n",
        "import time\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch.nn.functional as F\n",
        "import random\n",
        "import pandas as pd\n",
        "#満期の株価\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "#満期\n",
        "maturity = 5# @param\n",
        "\n",
        "#時間間隔\n",
        "dt=1/maturity#@param\n",
        "\n",
        "\n",
        "sigma_ave=0.3 # @param\n",
        "mu_ave=0.05-sigma_ave**2/2#@param\n",
        "S_0 = 100  # @param\n",
        "strike = 100  # @param\n",
        "branches_bin=2#@param\n",
        "\n",
        "up_bin =np.exp(mu_ave*dt+sigma_ave*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down_bin =np.exp(-2*sigma_ave*np.sqrt(dt))#@param\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "def stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "\n",
        "    return stock_price\n",
        "\n",
        "#2項モデルでのオプション価格を求め，　それを初期コストとする\n",
        "risk_neutral_measure=np.array([(1-up_bin*down_bin)/(up_bin-up_bin*down_bin), (up_bin-1)/(up_bin-up_bin*down_bin)])#リスク中立確率を求める\n",
        "Call_T=np.maximum(stock_price_T(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "\n",
        "for n in np.arange(maturity-1,-1,-1):\n",
        "    Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "\n",
        "#3項モデルでのパラメータを設定する\n",
        "branches = 3  # @param\n",
        "nu=0.005#@param\n",
        "zeta=0.35#@param\n",
        "# 上昇率\n",
        "up = np.exp(nu*dt+zeta*np.sqrt(dt))#@param\n",
        "# 下落率\n",
        "down = np.exp(-zeta*np.sqrt(dt))#@param\n",
        "\n",
        "\n",
        "#1の位で切り上げ\n",
        "init_cost=Call_T[0]\n",
        "\n",
        "\n",
        "init_cost\n",
        "\n",
        "#コールオプションの支払い\n",
        "def call(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(stock_price-strike,0)\n",
        "#プットオプションの支払い\n",
        "def put(strike=strike,stock_price=stock_price_T):\n",
        "    stock_price=stock_price_T()\n",
        "    return np.maximum(strike-stock_price,0)\n",
        "#パラメータから確率測度を計算\n",
        "\n",
        "def stock_price_T(maturity=maturity, branches=branches, up=up,down=down, S_0=S_0):\n",
        "    stock_price=np.array(S_0)\n",
        "    for _ in range(1,maturity+1):\n",
        "        stock_price=stock_price.reshape(-1,1)*np.array([up,up*down,up*down**2])\n",
        "\n",
        "    return stock_price\n",
        "stock_price_T()\n",
        "def param_to_prob(mu, sigma,nu=nu,zeta=zeta,dt=dt):\n",
        "  prob=np.array([1/2*(sigma/zeta)**2+np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu),1-(sigma/zeta)**2,1/2*(sigma/zeta)**2-np.sqrt(dt)/(2*zeta)*(mu-sigma**2/2-nu)]  )\n",
        "  assert np.min(prob)>=0#確率測度の定義を満たしているか確認\n",
        "  assert np.isclose(np.sum(prob),1,atol=1e-15)\n",
        "  return prob\n",
        "\n",
        "\n",
        "\n",
        "#最適ヘッジの計算\n",
        "def calculate_table(maturity, branches, up, down, S_0,  init_cost,prob_list,strike):\n",
        "    #初期条件\n",
        "    #maturity : 満期\n",
        "    #branches : 分岐数\n",
        "    #up : 上昇因子\n",
        "    #down : 下降因子\n",
        "    #S_0 : 初期株価\n",
        "    #init_cost : 初期コスト\n",
        "    #prob_matrix : 推移確率\n",
        "    #payoff_func : 支払い関数\n",
        "    assert (type(maturity)==int) & (maturity>0)#満期は正の整数\n",
        "    assert (type(branches)==int) & (branches>0)#分岐数は正の整数\n",
        "    assert up>1 #上昇因子は1より大きい実数\n",
        "    assert (1>down) & (down>0)#下降因子は0から1までの実数\n",
        "    assert S_0>=0\n",
        "    assert init_cost>=0\n",
        "    stock_price=torch.from_numpy(stock_price_T(maturity,branches,up,down,S_0)).cuda()\n",
        "    a_n=torch.ones_like(stock_price).cuda()\n",
        "    #コール\n",
        "    #b_n=torch.clamp(stock_price-strike, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-strike, min=0).cuda())**2\n",
        "    #ストラングル\n",
        "    #b_n=torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(80-stock_price, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #ブルスプレッド\n",
        "    #b_n=torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda()\n",
        "    #c_n=(torch.clamp(stock_price-80, min=0).cuda()-torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    #バタフライスプレッド\n",
        "    b_n=torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda()\n",
        "    c_n=(torch.clamp(stock_price-80, min=0).cuda()-2*torch.clamp(stock_price-100, min=0).cuda()+torch.clamp(stock_price-120, min=0).cuda())**2\n",
        "    for n in np.arange(maturity-1, 0,-1):\n",
        "        prob_tensor=prob_list[n]\n",
        "\n",
        "        Cond_Exp_a=torch.einsum('ij,ij->i', a_n, prob_tensor)\n",
        "        Cond_Exp_a_Delta_S=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_a_Delta_S_sq=torch.einsum('ij,ij->i', a_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1))**2, prob_tensor)\n",
        "        Cond_Exp_b=torch.einsum('ij,ij->i', b_n, prob_tensor)\n",
        "        Cond_Exp_b_Delta_S=torch.einsum('ij,ij->i', b_n*(stock_price-(stock_price[:,0]/up).reshape(-1,1)), prob_tensor)\n",
        "        Cond_Exp_c=torch.einsum('ij,ij->i', c_n, prob_tensor)\n",
        "        a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "        a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "        b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "        a_n = Cond_Exp_a - a_divide\n",
        "        b_n= Cond_Exp_b - a_b_divide\n",
        "        c_n= Cond_Exp_c - b_divide\n",
        "        a_n=a_n.reshape(branches**(n-1),branches)\n",
        "        b_n=b_n.reshape(branches**(n-1),branches)\n",
        "        c_n=c_n.reshape(branches**(n-1),branches)\n",
        "\n",
        "        stock_price=(stock_price[:,0]/up).reshape(branches**(n-1),branches)\n",
        "\n",
        "    stock_price=stock_price[0]\n",
        "    prob_tensor=prob_list[0]\n",
        "    Cond_Exp_a=a_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S=(a_n*(stock_price-S_0)).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_a_Delta_S_sq= (a_n*(stock_price-S_0)**2).squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b= b_n.squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_b_Delta_S=(b_n*(stock_price-S_0)).squeeze(0)@prob_tensor.squeeze(0)\n",
        "    Cond_Exp_c=c_n.squeeze(0)@ prob_tensor.squeeze(0)\n",
        "    a_divide=Cond_Exp_a_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_b_divide=(Cond_Exp_a_Delta_S * Cond_Exp_b_Delta_S) / (Cond_Exp_a_Delta_S_sq)\n",
        "    a_b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    b_divide=Cond_Exp_b_Delta_S ** 2 / (Cond_Exp_a_Delta_S_sq)\n",
        "    b_divide[Cond_Exp_a_Delta_S_sq<1e-20]=0\n",
        "    a_n = Cond_Exp_a - a_divide\n",
        "    b_n= Cond_Exp_b - a_b_divide\n",
        "    c_n= Cond_Exp_c - b_divide\n",
        "    Hedge_Error=a_n*init_cost**2-2*b_n*init_cost+c_n\n",
        "    pi_0=(Cond_Exp_b_Delta_S-Cond_Exp_a_Delta_S*init_cost)/Cond_Exp_a_Delta_S_sq\n",
        "    return Hedge_Error,pi_0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vra0PB6A4sNE",
        "outputId": "81dee3b2-e74c-47ab-8ac5-46a3d607b2fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "処理時間 : 2304.1789774959907,strike : 3000,loss : 36.775618341753\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3000.0</td>\n",
              "      <td>68517.0</td>\n",
              "      <td>5.372656e-13</td>\n",
              "      <td>0.03106</td>\n",
              "      <td>36.775618</td>\n",
              "      <td>2304.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0        1             2        3          4       5    6\n",
              "0  3000.0  68517.0  5.372656e-13  0.03106  36.775618  2304.0  0.0"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#期ごとのNN 2モデル, 多層化 これに決めた バタフライスプレッド 5\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import plotly\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "strike_range =[3000]\n",
        "#nn.Moduleのサブクラスとして定義する\n",
        "class Normalize(nn.Module):\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, dim=0, keepdim=True)\n",
        "        std = (torch.sqrt(torch.var(x, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        return (x - mean) / std\n",
        "normalize = Normalize()\n",
        "def tensor_to_standard(input_tensor):\n",
        "  return (input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "def decimal_to_base_n(n, base):\n",
        "    \"\"\"baseによって任意の進数表示ができる\"\"\"\n",
        "    if n == 0:\n",
        "        return 0\n",
        "    nums = []\n",
        "    while n:\n",
        "        n, r = divmod(n, base)\n",
        "        nums.append(str(r))\n",
        "    return int(''.join(reversed(nums)))\n",
        "df=pd.DataFrame()\n",
        "from tqdm import tqdm\n",
        "for strike in strike_range:\n",
        "    def stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0):\n",
        "        stock_price=np.array(S_0)\n",
        "        for _ in range(1,maturity+1):\n",
        "            stock_price=stock_price.reshape(-1,1)*np.array([up_bin,up_bin*down_bin])\n",
        "        return stock_price\n",
        "    #コール\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-strike,0)#満期の支払いを計算\n",
        "    #ストラングル\n",
        "    #Call_T=np.maximum(80-stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0),0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    #ブルスプレッド\n",
        "    #Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        #-np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\\\n",
        "    #バタフライスプレッド\n",
        "    Call_T=np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-80,0)\\\n",
        "        -2*np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-100,0)\\\n",
        "        +np.maximum(stock_price_T_bin(maturity=maturity, branches=branches_bin, up=up_bin,down=down_bin, S_0=S_0)-120,0)\n",
        "    for n in np.arange(maturity-1,-1,-1):\n",
        "        Call_T=Call_T.reshape(branches_bin**(n),branches_bin)@risk_neutral_measure\n",
        "    init_cost=Call_T[0]\n",
        "    end_epoch = []\n",
        "    prob_list_bust = []\n",
        "    df_weight = pd.DataFrame()\n",
        "\n",
        "    df_pi_0 = pd.DataFrame()\n",
        "    prob_df = []\n",
        "    pi_0s=[]\n",
        "    losses = []\n",
        "    weights = []\n",
        "    grads = []\n",
        "    error_True = []\n",
        "\n",
        "\n",
        "    def call(strike=strike, stock_price=stock_price_T):\n",
        "        stock_price = stock_price_T()\n",
        "        return np.maximum(stock_price - strike, 0)\n",
        "    #Heの初期化\n",
        "    def init_weights(m):\n",
        "        if isinstance(m, nn.Linear):\n",
        "            nn.init.xavier_normal_(m.weight.data, gain=nn.init.calculate_gain('relu'))#gain=np.sqrt(2)\n",
        "\n",
        "    model_params = np.array([[0.07, 0.35], [0.03, 0.25]])\n",
        "\n",
        "\n",
        "    models = model_params.shape[0]\n",
        "    torch.cuda.seed_all()\n",
        "    torch.manual_seed(0)\n",
        "\n",
        "    input_size = 9\n",
        "    hidden_size = 32\n",
        "    output_size = models\n",
        "\n",
        "    class NN(nn.Module):\n",
        "        def __init__(self):\n",
        "            super(NN, self).__init__()\n",
        "            self.fc_add1=nn.Linear(input_size,input_size)\n",
        "            self.fc_add2=nn.Linear(input_size,input_size)\n",
        "            self.layers = nn.Sequential()\n",
        "\n",
        "            # 入力層\n",
        "            #1層\n",
        "            self.layers.add_module(\"fc_add\", nn.Linear(input_size, input_size))\n",
        "\n",
        "\n",
        "            #2層\n",
        "            self.layers.add_module(f\"fc{0}\", nn.Linear(input_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{0}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{0}\", normalize)\n",
        "\n",
        "            #3層\n",
        "            self.layers.add_module(f\"fc{1}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{1}\", nn.ReLU())\n",
        "            self.layers.add_module(f\"st{1}\", normalize)\n",
        "\n",
        "            #4層\n",
        "            self.layers.add_module(f\"fc{2}\", nn.Linear(hidden_size,hidden_size))\n",
        "            self.layers.add_module(f\"relu{2}\", nn.ReLU())\n",
        "\n",
        "\n",
        "            # 出力層\n",
        "            self.layers.add_module(\"output\", nn.Linear(hidden_size, output_size))\n",
        "\n",
        "\n",
        "        def forward(self, x):\n",
        "            return self.layers(x)\n",
        "\n",
        "\n",
        "    nets = [NN().cuda() for _ in range(maturity)]\n",
        "    for net in nets:\n",
        "        net.apply(init_weights)\n",
        "\n",
        "\n",
        "\n",
        "    optimizers = [torch.optim.Adam(net.parameters(), lr=0.001) for net in nets]\n",
        "\n",
        "\n",
        "    num_epochs =10**5\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    t0 = time.perf_counter()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "        weight_tensor = torch.zeros(maturity, branches**(maturity-1), model_params.shape[0], requires_grad=True).cuda()\n",
        "        new_weight_tensor = weight_tensor.clone()\n",
        "\n",
        "        for n in np.arange(maturity-1, 0, -1):\n",
        "\n",
        "            S=(torch.from_numpy(stock_price_T(n,branches,up,down,S_0))/S_0).cuda().reshape(-1,1)\n",
        "            lattice_points=torch.arange(0,3**n,1).reshape(-1,1).cuda()\n",
        "            input_tensor=torch.concat([torch.log(S),torch.log(S)**2,torch.log(S)**3,\\\n",
        "                                torch.sqrt(S), torch.sqrt(S)**3 , torch.sqrt(S)**5,\\\n",
        "                                      (lattice_points),torch.sqrt(S*lattice_points),(S*lattice_points)**2],dim=1)\n",
        "            ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "\n",
        "            new_weight_tensor[n][0:3**n]=nn.Softmax(dim=1)(nets[n](ST_input_tensor.cuda().double()))\n",
        "\n",
        "        input_tensor=torch.tensor([[0,0,0,1,1,1,0,0,0],[0,0,0,1,1,1,0,0,0]]).cuda().double()\n",
        "        ST_input_tensor=(input_tensor-torch.mean(input_tensor, dim=0, keepdim=True))/(torch.sqrt(torch.var(input_tensor, dim=0, keepdim=True, unbiased=False)+1e-05))\n",
        "        new_weight_tensor[0][0]=nn.Softmax(dim=1)(nets[0](ST_input_tensor.double()))[0]\n",
        "        weight_tensor = new_weight_tensor\n",
        "\n",
        "        prob_tensor=torch.zeros(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\n",
        "        new_prob_tensor=prob_tensor.clone()\n",
        "        for m in range(models):\n",
        "            new_prob_tensor=new_prob_tensor+torch.ones(maturity, branches**(maturity-1), branches, requires_grad=True).cuda()\\\n",
        "                * torch.from_numpy(param_to_prob(model_params[m, 0], model_params[m, 1])).cuda()*new_weight_tensor[:,:,m].reshape(maturity,branches**(maturity-1),1)\n",
        "\n",
        "        new_prob_tensor\n",
        "        prob_list=[]\n",
        "        for n in range(new_prob_tensor.shape[0]):\n",
        "            prob_list.append(new_prob_tensor[n][0:branches**n].reshape(branches**n,branches))\n",
        "\n",
        "\n",
        "        loss = -calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[0]\n",
        "        pi_0=calculate_table(maturity, branches, up, down, S_0, init_cost, prob_list,strike)[1]\n",
        "        pi_0s.append(pi_0.item())\n",
        "        weights.append(weight_tensor.detach().cpu().numpy())\n",
        "        losses.append(-loss.item())\n",
        "        #if epoch % 1000==0:\n",
        "            #print(epoch,-loss.item())\n",
        "        #print(f'epoch : {epoch},loss : {-loss.item()}')\n",
        "        loss.backward()\n",
        "\n",
        "\n",
        "\n",
        "        for optimizer in optimizers:\n",
        "            optimizer.step()\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    elapsed_time=time.perf_counter() - t0\n",
        "    print(f'処理時間 : {elapsed_time},strike : {strike},loss : {losses[losses.index(max(losses))]}')\n",
        "\n",
        "    df=pd.concat([df,pd.DataFrame([strike,losses.index(max(losses)),weights[losses.index(max(losses))][0,0,0],\\\n",
        "                                   pi_0s[losses.index(max(losses))],losses[losses.index(max(losses))],int(elapsed_time),np.max(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)])]).T])\n",
        "\n",
        "\n",
        "    df.to_csv(f'df_t_x_non_Markov_3_custom_models_{model_params.shape[0]}_maturity_{maturity}_strike_{strike}.csv',index=False)\n",
        "    pd.DataFrame(weights[losses.index(max(losses))].reshape(int(np.size(weight_tensor.cpu().detach().numpy())/models),models))\\\n",
        "        .to_csv(f'weight_strike_{strike}_models_{model_params.shape[0]}_maturity_{maturity}_non_Markov.csv',index=False)\n",
        "    import numpy as np\n",
        "    import plotly.graph_objects as go\n",
        "\n",
        "    # 1万個のデータを準備\n",
        "    losses = np.array(losses)\n",
        "\n",
        "    # lossesの勾配を計算\n",
        "    gradient_losses = np.gradient(losses)\n",
        "\n",
        "    # インデックスの生成（1, 101, 201, ..., 9901）\n",
        "    indices = np.arange(1, len(losses), 100)\n",
        "\n",
        "    # lossesとgradient_lossesから指定のインデックスに対応するデータの抽出\n",
        "    selected_losses = losses[indices]\n",
        "    selected_gradient_losses = gradient_losses[indices]\n",
        "\n",
        "    # lossesとgradient_lossesから最大値を取得\n",
        "    max_loss = np.max(losses)\n",
        "    max_gradient_loss = np.max(gradient_losses)\n",
        "\n",
        "    # 最大値のインデックスを取得\n",
        "    index_max_loss = np.argmax(losses)\n",
        "    index_max_gradient_loss = np.argmax(gradient_losses)\n",
        "\n",
        "    # プロットの作成\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(losses)), y=losses, mode='lines', name='Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_losses, mode='markers', name='Selected Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_loss], y=[max_loss], mode='markers', marker=dict(size=10, color='Red'), name='Max Loss'))\n",
        "\n",
        "    # gradient_lossesの全データと抽出したデータをプロット\n",
        "    fig.add_trace(go.Scatter(x=np.arange(len(gradient_losses)), y=gradient_losses, mode='lines', name='Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=indices, y=selected_gradient_losses, mode='markers', name='Selected Gradient Losses'))\n",
        "    fig.add_trace(go.Scatter(x=[index_max_gradient_loss], y=[max_gradient_loss], mode='markers', marker=dict(size=10, color='Green'), name='Max Gradient Loss'))\n",
        "\n",
        "    # グラフのタイトルと軸ラベルの設定\n",
        "    fig.update_layout(title=f'ストライク {strike}の学習',\n",
        "                  xaxis_title='エポック数',\n",
        "                  yaxis_title='ヘッジ誤差')\n",
        "\n",
        "    # グラフをHTMLファイルとして保存\n",
        "    fig.write_html(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}.html')\n",
        "\n",
        "    # グラフの表示\n",
        "\n",
        "    step=1\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差' : losses[np.arange(1,len(losses),step)]},index=np.arange(1,len(losses),step))\n",
        "    losses[np.arange(1,len(losses),step)],np.arange(1,len(losses),step)\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses)[len(losses)-1000:len(losses)]},index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "    pd.DataFrame({'ヘッジ誤差の差' : np.gradient(losses[np.arange(1,len(losses),step)])},index=np.arange(1,len(losses),step))\n",
        "    pd.DataFrame(np.maximum.accumulate(losses),index=np.arange(1,len(losses)+step,step)).\\\n",
        "        to_csv(f'hedge_losses_maximum_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov.csv')\n",
        "    pd.DataFrame(np.gradient(np.maximum.accumulate(losses))[len(losses)-1000:len(losses)],index=np.arange(len(losses)-1000,len(losses),1)).\\\n",
        "        to_csv(f'hedge_losses_maximum_grad_strike_{strike}_models_{models}_maturity_{maturity}_non_Markov_final_1000.csv')\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Md_PKoU44sNF"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5sx3W6wP4sNF"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}